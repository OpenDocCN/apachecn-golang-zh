# 分析 Go 代码

评测是一种可用于测量计算机系统中使用的资源的实践。分析通常是为了了解程序中的 CPU 或内存利用率，以便优化执行时间、大小或可靠性。在本章中，除了分析之外，我们还将学习以下内容：

*   如何在 Go with`pprof`中分析请求
*   如何比较多个配置文件
*   如何读取生成的轮廓和火焰图

执行评测将帮助您推断出在函数中哪些地方可以进行改进，以及相对于整个系统而言，单个片段在函数调用中花费了多少时间。

# 理解剖析

分析 Go 代码是确定代码库中瓶颈位置的最佳方法之一。我们的计算机系统存在物理限制（CPU 时钟速度、内存大小/速度、I/O 读/写速度和网络吞吐量，举几个例子），但我们通常可以优化我们的程序，以更有效地利用我们的物理硬件。使用探查器获取计算机程序的概要文件后，将创建一个报告。此报告（通常称为概要文件）可以告诉您有关所运行程序的信息。您可能需要了解程序的 CPU 和内存利用率的原因有很多。下面列出了几个示例：

**CPU 评测原因：**

*   检查新版本软件的性能改进
*   验证每个任务使用了多少 CPU
*   限制 CPU 利用率以节省资金
*   了解延迟的来源

**内存配置原因：**

*   全局变量的不正确使用
*   未完成的 Goroutines
*   不正确的反射用法
*   大字符串分配

接下来我们将讨论探索仪器方法。

# 探索仪器方法学

`pprof`工具有许多不同的方法将评测合并到代码中。Go 语言创建者希望确保它在实现编写 performant 程序所需的评测时简单有效。我们可以在 Go 软件开发的许多阶段实现评测，即工程、新功能的创建、测试和生产。

重要的是要记住，评测确实会增加一点性能损失，因为在运行的二进制文件中会不断收集更多的度量。许多公司（包括谷歌）认为这种权衡是可以接受的。为 CPU 和内存分析增加 5%的额外开销是值得的，这样才能一致地编写性能良好的代码。

# 用 go 测试实现评测

您可以使用`go test`命令创建 CPU 和内存配置文件。如果您想比较多个测试运行的输出，这可能很有用。这些输出通常存储在长期存储器中，以便在更长的日期范围内进行比较。要执行测试的 CPU 和内存配置文件，请执行`go test -cpuprofile /tmp/cpu.prof -memprofile /tmp/mem.prof -bench`命令。

这将创建两个输出文件`cpu.prof`和`mem.prof`，这两个文件都将存储在`/tmp/`文件夹中。可以使用本章后面的*分析剖面*部分中的技术分析这些生成的剖面。

# 在代码中手动检测分析

如果您的代码中有一个特定的位置需要专门评测，那么您可以直接围绕该代码实现评测。如果您只想分析较小的代码段，如果您希望`pprof`输出更小、更简洁，或者如果您不想通过围绕代码的已知昂贵部分实施分析来增加额外的开销，那么这将特别有用。对于围绕代码库的不同段执行 CPU 和内存评测，有不同的方法。

分析特定代码块的 CPU 利用率如下所示：

```
function foo() {
pprof.StartCPUProfile()
defer pprof.StopCPUProfile()
...
code
...
}
```

分析特定代码块的内存利用率如下所示：

```
function bar() {
runtime.GC()
defer pprof.WriteHeapProfile()
...
code
...
}
```

如果我们进行有效的设计，进行有效的迭代，并使用下一节中的习惯用法实现评测，那么我们希望不必实现代码的各个片段，但很高兴知道，这始终是评测代码和检索有意义输出的潜在选项。

# 分析正在运行的服务代码

在 Go 代码中实现评测最常用的方法是在 HTTP 处理程序函数中启用分析器。这对于调试实时生产系统非常有用。能够实时分析您的生产系统可以让您根据真实的实时生产数据而不是本地开发环境做出决策。

有时，只有当特定系统的数据数量级达到特定规模时，才会发生错误。能够有效处理 1000 个数据点的方法或函数可能无法在运行该函数或方法的底层硬件上有效处理 1000000 个数据点。当在发生变化的硬件上运行时，这一点尤为重要。无论您运行的 Kubernetes 具有嘈杂的邻居、具有未知规格的新物理硬件，还是具有新版本的代码或第三方库，了解更改对性能的影响对于创建可靠性和弹性至关重要。

能够从生产系统接收数据（最终用户及其数据的数量级可能大于您在本地使用的数量级）可以帮助您提高性能，从而影响到您在本地迭代时可能从未发现的最终用户。

如果我们想在 HTTP 处理程序中实现`pprof`库，我们可以使用`net/http/pprof`库。这可以通过将`_ "net/http/pprof"`导入主程序包来实现。

然后，HTTP 处理程序将为您的评测注册 HTTP 处理程序。确保您没有在公开的 HTTP 服务器上执行此操作；程序配置文件的崩溃会暴露一些严重的安全漏洞。`pprof`包的索引显示了使用此包时可用的路径。以下是`pprof`工具索引的截图：

![](assets/f6f83adb-86ca-49aa-83a5-38ed0d43d3dc.png)

我们可以看看公开的 HTTP`pprof`路径及其描述。路径和相关说明可在下表中找到：

| **名称** | **HTTP 路径** | **说明** |
| `allocs` | `/debug/pprof/allocs` | 内存分配信息。 |
| `block` | `/debug/pprof/block` | 有关 goroutines 块等待位置的信息。这通常发生在同步原语上。 |
| `cmdline` | `/debug/pprof/cmdline` | 调用二进制文件的命令行的值。 |
| `goroutine` | `/debug/pprof/goroutine` | 当前正在运行的 goroutine 的堆栈跟踪。 |
| `heap` | `/debug/pprof/heap` | 内存分配采样（用于监视内存使用和泄漏）。 |
| `mutex` | `/debug/pprof/mutex` | 争用互斥堆栈跟踪。 |
| `profile` | `/debug/pprof/profile` | CPU 配置文件。 |
| `symbol` | `/debug/pprof/symbol` | 请求程序计数器。 |
| `threadcreate` | `/debug/pprof/threadcreate` | 操作系统线程创建堆栈跟踪。 |
| `trace` | `/debug/pprof/trace` | 当前程序跟踪。这将在[第 13 章](12.html)、*跟踪 Go 代码*中进行深入讨论。 |

在下一节中，我们将讨论 CPU 评测。

# CPU 配置简介

让我们在一个简单的 Go 程序上执行一些示例评测，以了解分析器是如何工作的。我们将创建一个带有几个睡眠参数的示例程序，以查看不同函数调用的计时：

1.  首先，我们实例化我们的包并添加所有导入：

```
import (
    "fmt"
    "io"
    "net/http"
    _ "net/http/pprof"
    "time"
)
```

2.  接下来，在我们的`main`函数中，我们有一个 HTTP 处理程序，它有两个作为处理程序一部分调用的睡眠函数：

```
func main() {
    Handler := func(w http.ResponseWriter, req *http.Request) {
        sleep(5)
        sleep(10)
        io.WriteString(w, "Memory Management Test")
    }
    http.HandleFunc("/", Handler)
    http.ListenAndServe(":1234", nil)
}
```

我们的`sleep`函数只是在特定的毫秒时间内休眠，并打印结果输出：

```
func sleep(sleepTime int) {
    time.Sleep(time.Duration(sleepTime) * time.Millisecond)
    fmt.Println("Slept for ", sleepTime, " Milliseconds")
}
```

3.  当我们运行程序时，我们会看到输出`go run httpProfiling.go`。要从这个特定代码生成一个配置文件，我们需要调用`curl -s "localhost:1234/debug/pprof/profile?seconds=10" > out.dump`。这将运行一个配置文件 10 秒钟，并将结果返回到一个名为`out.dump`的文件。默认情况下，`pprof`工具将运行 30 秒，并将二进制文件返回到`STDOUT`。我们希望确保将此测试的时间限制在测试持续时间合理的范围内，并且我们需要重定向输出，以便能够捕获一些有意义的内容，以便在分析工具中查看。
4.  接下来，我们为我们的函数生成一个测试负载。我们可以使用 ApacheBench 来完成这项任务，生成 5000 个并发性为 10 的请求；我们使用`ab -n 5000 -c 10 http://localhost:1234/`进行设置。
5.  一旦我们从这个测试中得到了输出，我们就可以查看我们的`out.dump`文件`go tool pprof out.dump`。这将带您进入探查器。这是 C++剖析器的一个微小变体。这个工具有很多功能。
6.  我们可以使用`topN`命令查看我们生成的配置文件中包含的顶部*N*样本，如下图所示：

![](assets/2559344c-6b24-4454-88e5-f3b963485d80.png)

在执行探查器时，Go 大约每秒停止程序 100 次。在此期间，它会将程序计数器记录在 goroutine 的堆栈上。我们还可以使用累积标志`(-cum)`，以便根据我们当前配置文件采样中的累积值进行排序：

![](assets/e0b8c731-8d0f-4b85-ae22-87ef49d77237.png)

7.  我们还能够以图形形式显示跟踪的可视化表示。在我们确保安装了`graphviz`软件包后（它应该包含在您的软件包管理器中，或者可以从[下载）http://www.graphviz.org/](http://www.graphviz.org/) 只需输入`web`命令）

这将为我们提供从程序中生成的配置文件的可视化表示：

![](assets/f4b4289d-63a6-459f-817e-fd642cceee4c.png)

概要文件中的红色框是对请求流影响最大的代码路径。我们可以查看这些框，并且，正如我们所期望的，我们可以看到我们的示例程序中有很大一部分在睡眠和将响应写回客户端时需要时间。我们可以通过传递我们想要查看 web 图形的函数的名称来查看相同 web 格式中的特定函数。例如，如果我们想查看`sleep`函数的详细视图，只需键入`(pprof) web sleep`命令即可。

8.  然后我们会得到一个`SVG`，图像集中在睡眠呼叫上：

![](assets/66241c91-a271-45ea-8575-4766a652208d.png)

9.  在我们得到这个故障后，我们可能想看看睡眠功能的实际执行情况。我们可以在`pprof`中使用`list`命令，以获得描述`sleep`命令调用及其后续调用的输出。下面的屏幕截图显示了这一点；为简洁起见，代码缩短为：

![](assets/89c2dac7-abe2-414f-9738-993f76fafc9a.png)

能够将我们正在做的工作分解为可分段的块，可以从利用率的角度告诉我们很多关于我们需要开发的方向

在下一节中，我们将看到内存分析是什么。

# 内存配置简介

我们可以执行与前一节中使用内存进行的 CPU 测试类似的操作。让我们看看使用测试功能的另一种处理配置文件的方法。让我们使用我们在[第 2 章](02.html)中创建的一个示例，*数据结构和算法-*函数。我们可以使用已经为这个特定函数创建的基准测试，并向这个特定测试添加一些内存分析。我们可以执行`go test -memprofile=heap.dump -bench`命令。

我们将看到一个类似于我们在[第 2 章](02.html)、*数据结构和算法*中看到的输出：

![](assets/6e4f4592-7126-4df9-9b54-48cc7363664b.png)

唯一的区别是，现在我们将获得此测试中的堆配置文件。如果我们使用探查器查看它，我们将看到有关堆使用情况的数据，而不是 CPU 使用情况的数据。我们还可以看到该程序中每个函数的内存分配。下图说明了这一点：

![](assets/0addac7e-6218-4608-8628-cad13ac28e26.png)

这是很有帮助的，因为它使我们能够看到此代码每个部分生成的堆大小。我们还可以看看最重要的累积内存分配：

![](assets/df629a1d-7502-4fba-88f8-41e8e3219e28.png)

随着我们的程序变得越来越复杂，了解内存利用率的状态变得越来越重要。在下一节中，我们将讨论如何使用上游`pprof`扩展我们的评测功能。

# 具有上游 pprof 的扩展功能

如果我们希望在默认情况下能够使用其他功能，我们可以使用上游`pprof`二进制文件来扩展配置文件中的视图：

1.  我们可以通过调用`go get github.com/google/pprof`来检索它。`pprof`工具有两种不同的调用方法。我们可以使用报表生成方式生成所需格式的文件（目前支持的格式有`.dot`、`.svg`、`.web`、`.png`、`.jpg`、`.gif`、`.pdf`等）。我们还可以使用交互式终端格式，其方式与我们在前面关于 CPU 和内存配置的部分中所做的类似。最后一种也是最常用的方法是使用 HTTP 服务器。此方法涉及托管 HTTP 服务器，该服务器以易于理解的格式包含许多相关输出。

2.  一旦我们通过`go get`检索到二进制文件，我们就可以通过 web 界面调用它，查看我们之前生成的输出：`pprof -http=:1234 profile.dump`。

3.  然后，我们可以访问新可用的 UI，查看默认`pprof`工具中未内置的特性和功能。此工具提供的几个关键亮点如下：
    *   一个 regex 可搜索表单字段，用于帮助搜索必要的分析元素
    *   一个下拉视图菜单，用于轻松查看可用的不同分析工具
    *   用于显示配置文件中的样本的样本下拉列表
    *   用于隐藏/显示请求流不同部分的优化过滤器

将所有这些工具用于分析，有助于使分析过程更加简化。如果我们想查看运行任何调用名称中带有`fmt`的调用所花费的时间，我们可以使用带有正则表达式过滤器的示例视图，它将突出显示`fmt`调用，如下面的屏幕截图所示：

![](assets/dd1b454e-ebb1-4ded-aaa4-a57165b00f4a.png)

根据这些值进行过滤有助于缩小性能不佳函数的范围

# 比较多个配置文件

分析的一个非常好的特性是，您可以相互比较分析。如果我们从同一个程序中有两个单独的度量，我们可以确定我们所做的更改是否对系统产生了积极影响。让我们稍微扩展一下 HTTP 睡眠计时功能：

1.  让我们添加一些额外的导入：

```
package main

import (
  "fmt"
  "net/http"
  _ "net/http/pprof"
  "strconv"
  "time"
)
```

2.  接下来，我们将扩充我们的处理程序，以获取`time`的查询字符串参数：

```
func main() { 
    Handler := func(w http.ResponseWriter, r *http.Request) {
        sleepDuration := r.URL.Query().Get("time")
        sleepDurationInt, err := strconv.Atoi(sleepDuration)
        if err != nil {
            fmt.Println("Incorrect value passed as a query string for time")
            return
        }
        sleep(sleepDurationInt)
        fmt.Fprintf(w, "Slept for %v Milliseconds", sleepDuration)
    } 
    http.HandleFunc("/", Handler)
    http.ListenAndServe(":1234", nil)
}
```

3.  我们将保持睡眠功能完全相同：

```
func sleep(sleepTime int) {
    time.Sleep(time.Duration(sleepTime) * time.Millisecond)
    fmt.Println("Slept for ", sleepTime, " Milliseconds")
}
```

4.  现在我们有了这个额外的功能，只需将一个查询参数传递给 HTTP 处理程序，就可以获得具有不同时间的多个配置文件：
    *   我们可以运行新的定时分析工具：

```
go run timedHttpProfiling.go
```

```
curl -s "localhost:1234/debug/pprof/profile?seconds=20" > 5-millisecond-profile.dump
```

```
ab -n 10000 -c 10 http://localhost:1234/?time=5
```

```
curl -s "localhost:1234/debug/pprof/profile?seconds=20" > 10-millisecond-profile.dump
```

```
ab -n 10000 -c 10 http://localhost:1234/?time=10
```

5.  我们现在有两个单独的配置文件可用，它们存储在`5-millisecond-profile.dump`和`10-millisecond-profile.dump`中。我们可以使用与以前相同的工具来比较，设置基本配置文件和辅助配置文件。以下屏幕截图说明了这一点：

![](assets/fa125aa7-f40e-4fcc-b0f1-f7de7862cb9b.png)

通过比较配置文件，我们可以了解更改对系统的影响。

让我们在下一节继续讨论火焰图。

# 在 pprof 范围内解释火焰图

上游`pprof`包中最有用的工具之一是火焰图。火焰图是一种固定速率采样可视化，有助于确定轮廓中的热代码路径。随着程序变得越来越复杂，配置文件变得越来越大。通常很难准确地知道什么代码路径消耗了最多的 CPU，或者，正如我常说的，*帐篷中的长杆*。

Flame graphs 最初由 Netflix 的 Brendan Gregg 开发，用于解决 MySQL 的 CPU 利用率问题。这种可视化的出现帮助许多程序员和系统管理员确定他们的程序中延迟的来源。`pprof`二进制生成冰柱式（火焰向下）火焰图。在火焰图中，我们将数据可视化到特定的框架中：

*   *x*轴是根据我们的要求采集的所有样本
*   y 轴显示堆栈上的帧数，也称为堆栈深度
*   框的宽度显示特定函数调用使用的 CPU 总时间

这三件事一起可视化有助于确定程序的哪个部分引入的延迟最大。您可以在`http://localhost:8080/ui/flamegraph`处访问`pprof`配置文件的火焰图部分。下图显示了此类火焰图的示例：

![](assets/8be26f48-4577-485d-999c-888ddc547d29.png)

如果我们看看[第 2 章](02.html)*数据结构和算法*中的`bubbleSort`示例，我们可以在测试中看到占用 CPU 时间的不同位的分解。在交互式 web 模式下，我们可以将鼠标悬停在每个示例上，验证它们的持续时间和执行时间百分比。

在下一节中，我们将看到如何检测 Go 中的内存泄漏。

# 检测 Go 中的内存泄漏

正如在[第 8 章](08.html)的*内存对象分配*一节中所讨论的，Go 中的*内存管理，我们可以使用大量工具查看当前正在执行的程序的当前内存统计信息。在本章中，我们还将学习如何使用 pprof 工具进行分析。更常见的 Go 内存泄漏之一是 Goroutine 的无限创建。当您过载了一个未缓冲的通道，或者您有一个具有大量并发性的抽象，产生了新的 goroutine，但没有完成时，这种情况经常发生。goroutine 占用的空间非常小，系统通常会产生大量 goroutine，但它们最终会有一个上限，在生产环境中尝试对程序进行故障排除时，很难找到这个上限。*

在以下示例中，我们将查看具有泄漏抽象的无缓冲通道：

1.  我们首先初始化包并导入必要的依赖项：

```
package main

import (
 "fmt"
 "net/http"

 _ "net/http/pprof"                                                                   
 "runtime"
 "time"
)
```

2.  在我们的主函数中，我们处理 HTTP 侦听和服务`leakyAbstraction`函数。我们通过 HTTP 提供服务，以便更容易看到 Goroutine 数量的增长：

```
func main() {
 http.HandleFunc("/leak", leakyAbstraction)
 http.ListenAndServe("localhost:6060", nil)
}  
```

3.  在我们的`leakyAbstraction`函数中，我们首先初始化一个无缓冲字符串通道。然后我们无休止地迭代一个 for 循环，将 goroutine 的数量写入 HTTP 响应编写器，并将`wait()`函数的结果写入通道：

```
func leakyAbstraction(w http.ResponseWriter, r *http.Request) {
 ch := make(chan string)                                                                

 for {
   fmt.Fprintln(w, "Number of Goroutines: ", runtime.NumGoroutine())
   go func() { ch <- wait() }()
 }          
}
```

4.  我们的`wait()`函数休眠 5 微秒并返回一个字符串：

```
func wait() string {
 time.Sleep(5 * time.Microsecond)
 return "Hello Gophers!"
}
```

这些函数一起将生成 goroutines，直到运行时不再能够生成 goroutines 并死亡。我们可以通过执行以下命令运行服务器来测试这一点：

```
go run memoryLeak.go
```

服务器运行后，在单独的终端窗口中，我们可以使用以下命令向服务器发出请求：

```
curl localhost:6060/leak
```

`curl`命令将打印在服务器关闭之前生成的 goroutine 数：

![](assets/e971d565-e6a6-4825-980c-71da2d27ecba.png)

请注意，此请求可能需要一段时间，具体取决于您的系统规格。这没关系，它说明了您的程序可供使用的 goroutine 的数量。

使用本章中学习的技术，我们将能够通过 pprof 进一步调试内存问题，但了解底层问题将有助于我们避免内存问题。

编写此示例是为了显式显示内存泄漏，但如果我们想使此可执行文件不泄漏 goroutines，则必须修复两件事：

*   我们的无界 for 循环很可能有一个界
*   我们可以添加一个缓冲通道，以确保我们能够处理通过该通道传入的所有生成的 goroutine

# 总结

在本章中，我们了解了配置文件是什么以及如何使用`pprof`生成配置文件。您还学习了如何使用不同的方法分析配置文件，如何比较配置文件，以及如何读取性能火焰图。能够在生产环境中执行此操作将帮助您保持稳定性，提高性能，并为最终用户提供更好的最终用户体验。在下一章中，我们将讨论另一种分析代码跟踪的方法。

# 跟踪 Go 代码

跟踪 Go 程序是检查 Go 程序中功能和服务之间互操作性的一种非常好的方法。跟踪允许您通过您的系统传递上下文，并评估您在哪里受到阻碍，无论是第三方 API 调用、慢速消息队列还是*O*（*n*<sup>2</sup>函数。跟踪将帮助您找到瓶颈所在的位置。在本章中，我们将学习以下内容：

*   实施追踪的过程
*   跟踪取样的过程
*   解释追踪的过程
*   比较痕迹的过程

能够实现跟踪和解释结果将有助于开发人员理解和排除其分布式系统的故障。

# 实现跟踪工具

Go 的并发模型使用 goroutines，非常强大。具有高并发性的缺点之一是，在尝试调试该高并发模型时会遇到困难。为了避免这种困难，语言创造者创造了`go tool trace`。然后，他们在 Go 版本 1.5 中发布了该版本，以便能够调查和解决并发问题。Go 跟踪工具钩住 goroutine 调度程序，以便它能够生成关于 goroutine 的有意义的信息。您可能希望通过 Go 跟踪调查的一些实施细节包括：

*   延迟
*   资源争夺
*   并行性差
*   I/O 相关事件
*   系统调用
*   渠道
*   锁
*   **垃圾收集****垃圾收集**
*   戈罗季斯

解决所有这些问题将帮助您构建一个更具弹性的分布式系统。在下一节中，我们将讨论跟踪格式以及它如何适用于 Go 代码。

# 理解跟踪格式

Go 跟踪可以有大量信息，每秒可以捕获大量请求。因此，跟踪以二进制格式捕获。跟踪输出的结构是静态的。在下面的输出中，我们可以看到轨迹遵循它们定义的特定模式，事件通过十六进制前缀和特定跟踪事件的一些信息进行分类。查看此跟踪格式将帮助我们了解如何使用 Go 团队提供给我们的工具存储和检索跟踪事件：

```
Trace = "gotrace" Version {Event} .

Event = EventProcStart | EventProcStop | EventFreq | EventStack | EventGomaxprocs | EventGCStart | EventGCDone | EventGCScanStart | EventGCScanDone | EventGCSweepStart | EventGCSweepDone | EventGoCreate | EventGoStart | EventGoEnd | EventGoStop | EventGoYield | EventGoPreempt | EventGoSleep | EventGoBlock | EventGoBlockSend | EventGoBlockRecv | EventGoBlockSelect | EventGoBlockSync | EventGoBlockCond | EventGoBlockNet | EventGoUnblock | EventGoSysCall | EventGoSysExit | EventGoSysBlock | EventUser | EventUserStart | EventUserEnd .

EventProcStart = "\x00" ProcID MachineID Timestamp .
EventProcStop = "\x01" TimeDiff .
EventFreq = "\x02" Frequency .
EventStack = "\x03" StackID StackLen {PC} .
EventGomaxprocs = "\x04" TimeDiff Procs .
EventGCStart = "\x05" TimeDiff StackID .
EventGCDone = "\x06" TimeDiff .
EventGCScanStart= "\x07" TimeDiff .
EventGCScanDone = "\x08" TimeDiff .
EventGCSweepStart = "\x09" TimeDiff StackID .
EventGCSweepDone= "\x0a" TimeDiff .
EventGoCreate = "\x0b" TimeDiff GoID PC StackID .
EventGoStart = "\x0c" TimeDiff GoID .
EventGoEnd = "\x0d" TimeDiff .
EventGoStop = "\x0e" TimeDiff StackID .
EventGoYield = "\x0f" TimeDiff StackID .
EventGoPreempt = "\x10" TimeDiff StackID .
EventGoSleep = "\x11" TimeDiff StackID .
EventGoBlock = "\x12" TimeDiff StackID .
EventGoBlockSend= "\x13" TimeDiff StackID .
EventGoBlockRecv= "\x14" TimeDiff StackID .
EventGoBlockSelect = "\x15" TimeDiff StackID .
EventGoBlockSync= "\x16" TimeDiff StackID .
EventGoBlockCond= "\x17" TimeDiff StackID .
EventGoBlockNet = "\x18" TimeDiff StackID .
EventGoUnblock = "\x19" TimeDiff GoID StackID .
EventGoSysCall = "\x1a" TimeDiff StackID .
EventGoSysExit = "\x1b" TimeDiff GoID .
EventGoSysBlock = "\x1c" TimeDiff .
EventUser = "\x1d" TimeDiff StackID MsgLen Msg .
EventUserStart = "\x1e" TimeDiff StackID MsgLen Msg .
EventUserEnd = "\x1f" TimeDiff StackID MsgLen Msg .
```

有关 Go 执行跟踪程序的更多信息，请参见 Dmitry Vyukov 在[上发布的原始规范文件 https://docs.google.com/document/u/1/d/1FP5apqzBgr7ahCCgFO-yoVhk4YZrNIDNf9RybngBc14/pub](https://docs.google.com/document/u/1/d/1FP5apqzBgr7ahCCgFO-yoVhk4YZrNIDNf9RybngBc14/pub) 。

能够看到跟踪的所有这些元素可以帮助我们理解如何将跟踪分解为原子块。在下一节中，我们将讨论跟踪收集。

# 理解跟踪收集

能够收集跟踪对于在分布式系统中实现跟踪是不可或缺的。如果我们不把这些痕迹集中在某个地方，我们就无法按比例理解它们。我们可以使用三种方法收集跟踪数据：

*   通过调用`trace.Start`和`trace.Stop`手动调用数据跟踪
*   使用测试标志`-trace=[OUTPUTFILE]`
*   检测`runtime/trace`包

为了理解如何在代码中实现跟踪，让我们来看一个简单的示例程序：

1.  我们首先实例化我们的包并导入必要的包：

```
package main

import (
    "os"
    "runtime/trace"
)
```

2.  然后我们调用`main`函数。我们将跟踪输出写入一个文件`trace.out`，稍后将使用该文件：

```
func main() {

    f, err := os.Create("trace.out")
    if err != nil {
        panic(err)
    } 

    defer f.Close()
```

3.  接下来，我们实现我们希望在程序中使用的跟踪，并将跟踪的结束推迟到函数返回：

```
    err = trace.Start(f)
    if err != nil {
        panic(err)
    } 

    defer trace.Stop()
```

4.  然后我们编写我们想要实现的代码。我们这里的示例只是在匿名函数中通过通道简单传递字符串`"Hi Gophers"`：

```
    ch := make(chan string)
    go func() {
        ch <- "Hi Gophers"
    }()
    <-ch
}
```

现在，我们已经围绕我们的（公认简单的）程序实现了跟踪，我们需要执行我们的程序来生成跟踪输出：

![](assets/e1bc51c4-054c-4a88-9e51-22e14d29dcc6.png)

5.  要查看跟踪，您可能需要安装其他软件包。对于我正在测试的 Fedora 系统，我必须安装一个额外的`golang-misc`包：`sudo dnf install golang-misc`。
6.  创建跟踪后，可以使用`go tool trace trace.out`命令打开创建的跟踪。

这使您可以启动将为跟踪输出提供服务的 HTTP 服务器。我们可以在以下屏幕截图中看到此输出：

![](assets/b54e468f-f12c-4783-afa8-7158f541f7e1.png)

我们可以在 Chrome 浏览器中看到结果跟踪输出。值得一提的是，我们需要使用兼容的浏览器，即 Chrome。在编写本书时，Firefox 将生成一个空白页面用于跟踪输出。以下是 Chrome 浏览器中跟踪的输出：

![](assets/2cb0717a-8035-40ef-8f40-549a81db2ea7.png)

这个 HTML 页面为您提供了一系列不同的有用输出选项。让我们在下表中逐一查看：

| **链路** | **说明** |
| 查看跟踪 | 查看 GUI 跟踪输出。 |
| Goroutine 分析 | 显示不同的 goroutine 信息。 |
| 网络阻塞配置文件 | 显示网络阻塞；可以创建单独的配置文件。 |
| 同步阻塞配置文件 | 显示同步阻塞；可以创建单独的配置文件。 |
| 系统调用阻塞配置文件 | 显示系统调用阻塞；可以创建单独的配置文件。 |
| 调度程序延迟配置文件 | 显示与调度程序关联的所有延迟；可以创建单独的配置文件。 |
| 用户定义的任务 | 允许查看任务数据类型；用于跟踪用户定义的逻辑操作。这是使用`trace.NewTask()`格式调用的。 |
| 用户定义区域 | 允许查看区域数据类型；用于跟踪代码区域。这是使用`trace.WithRegion()`格式调用的。 |
| 最小变异子利用率 | 创建一个可视化绘图，显示垃圾收集器从程序中窃取工作的时间和地点。这有助于您了解生产服务是否受 GC 约束。 |

我们可以从查看 web 浏览器中的跟踪开始：

![](assets/edd1f3d9-8df0-4a17-bbe4-f0c54cd30120.png)

查看这些痕迹时，我们可以做的第一件事是查看帮助菜单，该菜单位于屏幕右上角的问号框中。此信息菜单为我们提供了跟踪工具功能的大量描述：

![](assets/8172c4c6-9077-4281-a9a6-f7f0ad7a4991.png)

能够在跟踪窗口中快速有效地移动将帮助您快速查看跟踪。当您试图快速排除生产问题时，这会非常有帮助。

# 跟踪窗口中的移动

使用经典的*WASD*移动键（灵感来源于许多第一人称角色扮演视频游戏），我们可以在轨迹上移动。移动键描述如下：

*   *W*键放大轨迹的计时窗口。
*   *S*键将缩小。
*   *A*键在时间上向后移动。
*   *D*键在时间上向前移动。通过点击和拖动鼠标，我们也可以在时间上来回移动。

使用鼠标指针选择器或单击数字键可以操纵计时信息。以下要点列出了键盘更改：

*   *1*键允许我们选择要检查的跟踪部分
*   *2*键允许我们平移
*   *3*键调用缩放功能
*   *4*键允许我们选择特定的时间

我们现在可以使用*/*键搜索跟踪，使用*键输入*键逐步搜索结果

屏幕右侧还提供了文件大小统计、度量、帧数据和输入延迟窗口。单击这些按钮时，将打开一个弹出窗口，告诉您跟踪中每个特定统计信息的更多详细信息。

如果单击跟踪中 goroutines 行中的蓝色区域，我们可以查看 goroutines 的一些可用统计信息：

*   `GCWaiting`，这是正在等待的垃圾收集运行量（当前值为 0）
*   可运行 goroutine 的数量（当前值为 1）
*   正在运行的 goroutine 数（当前值为 1）

我们可以在下面的屏幕截图中看到 goroutines 可用统计数据的样本：

![](assets/f2a6c91a-b495-44e7-b78c-7bb9c4065b31.png)

goroutine 信息有助于最终用户调试程序。在 Go trace 工具中查看 goroutine 可以帮助我们确定 goroutine 何时在争夺竞争。它可能正在等待通道清除，可能被系统调用阻止，或者可能被调度程序阻止。如果有许多 goroutine 处于等待状态，这意味着程序可能创建了太多 goroutine。这可能会导致计划程序被过度分配。访问所有这些信息可以帮助我们做出明智的决定，如何更好地编写程序，更有效地利用 goroutines。

单击堆行中的橙色条将显示堆信息：

![](assets/04865725-43d9-47f1-86f3-2b84abe7321a.png)

在选定的时间（0.137232），我们可以看到有 425984 字节，或大约 425KB，分配给堆。知道当前分配给堆的内存量可以告诉我们程序中是否存在内存争用。评测（正如我们在[第 12 章](12.html)中所了解的，*评测 Go 代码*通常是查看堆信息的更好方法，但对跟踪上下文中的分配有一个大致的了解通常会有所帮助。

接下来我们可以查看线程信息。单击活动线程（跟踪的 Threads 行中的洋红块）将显示 InSyscall 和 Running 状态下的线程数：

![](assets/4d9b9579-f430-4d23-a18c-31aa5a04a684.png)

了解正在运行的操作系统线程的数量以及当前有多少线程被系统调用阻止是很有帮助的。

接下来，我们可以查看每个正在运行的进程。单击该过程将告诉您以下屏幕截图中显示的所有详细信息。如果将鼠标悬停在跟踪底部窗格中的一个事件上，您将能够看到进程是如何联系在一起的，如以下屏幕截图中的红色箭头所示：

![](assets/f84eef16-2487-4c23-97a0-917f9475ce61.png)

了解流程的端到端流程通常可以帮助您诊断问题流程。在下一节中，我们将学习如何探索类似的跟踪。

# 类迹的探索

Go 工具跟踪还可以生成四种不同类型的跟踪，这些跟踪可能与您的故障排除需求相关：

*   `net`：网络阻塞配置文件
*   `sync`：同步阻塞配置文件
*   `syscall`：系统调用阻塞配置文件
*   `sched`：调度器延迟配置文件

让我们来看一个关于如何在 Web 服务器上使用这些跟踪配置文件的示例：

1.  首先，我们初始化`main`并导入必要的包。请注意在 AUTT1 中显式包名称的空白标识符。这是为了确保我们可以进行跟踪调用：

```
package main

import (
    "io"
    "net/http"
    _ "net/http/pprof"
    "time"
)

```

2.  接下来，我们将设置一个简单的 web 服务器，该服务器将等待五秒钟并向最终用户返回一个字符串：

```
func main() {

   handler := func(w http.ResponseWriter, req *http.Request) {
       time.Sleep(5 * time.Second)
       io.WriteString(w, "Network Trace Profile Test")
    }

    http.HandleFunc("/", handler)
    http.ListenAndServe(":1234", nil)
}
```

3.  当我们通过执行`go run netTracePprof.go`来运行我们的服务器后，我们可以跟踪：`curl localhost:1234/debug/pprof/trace?seconds=10 > trace.out`。我们可以在下面的屏幕截图中看到我们的`curl`的输出：

![](assets/fee7866d-9776-4db5-87da-bbd466be6431.png)

4.  同时，在另一个终端中，我们可以在示例 Web 服务器`curl localhost:1234/`上请求`/`路径。然后，我们将在运行跟踪的目录中返回一个`trace.out`文件。然后我们可以使用`go tool trace trace.out`打开跟踪。然后我们将看到跟踪结果。利用生成的 HTTP 页面中的网络阻塞配置文件，我们可以看到网络阻塞配置文件的跟踪：

![](assets/57aa695e-104a-4342-b378-462014acf963.png)

正如预期的那样，我们看到了 5 秒钟的等待，因为这是我们为这个特定 web 请求添加到处理程序函数中的等待时间。如果我们愿意，我们可以下载此配置文件并在[第 12 章](12.html)、*评测 Go 代码*中讨论的上游`pprof`工具中查看。在跟踪 HTML 窗口中，web 配置文件旁边有一个下载按钮：

![](assets/7657e853-acb9-4f88-bcf3-f34514fd2bf7.png)

在我们下载了这个配置文件后，我们可以使用[第 12 章](12.html)中安装的上游`pprof`工具*评测 Go 代码*查看一下：

```
$ pprof -http=:1235 ~/Downloads/io.profile
```

然后我们可以看看火焰图：

![](assets/c94a6a96-e73e-40c0-9336-c38e26c70822.png)

我们可以在以下屏幕截图中看到 peek UI：

![](assets/598d77a6-10b2-4875-bd88-1b41b5549789.png)

flame 图和 peek UI 都有助于使这些复杂的调试视图更加简洁。在下一节中，我们将看到 Go 中的分布式跟踪是什么。

# 分布式跟踪

实施和调查 Go 程序的单个跟踪是一项富有成效的工作，它可以提供大量数据输出，从而导致对我们程序的请求。随着企业拥有越来越多的分布式代码库，其中包含许多复杂的调用，这些调用都可以彼此互操作，因此从长远来看，跟踪单个调用是不可行的。有两个项目试图帮助进行 Go 分布式跟踪，它们是 OpenCensus Go 库和 OpenTelemetry 库：

*   `opencensus-go`：[https://github.com/census-instrumentation/opencensus-go](https://github.com/census-instrumentation/opencensus-go)
*   `opentracing-go`：[https://github.com/opentracing/opentracing-go](https://github.com/opentracing/opentracing-go)

这些项目的维护人员已经决定将这两个项目合并，并开始在一个名为 OpenTelemetry 的代码库上工作。这个新的代码库将允许跨多种语言和基础设施简化分布式跟踪的集成。您可以在[上阅读有关 OpenTelemetry 的 Go 实现的更多信息 https://github.com/open-telemetry/opentelemetry-go](https://github.com/open-telemetry/opentelemetry-go) 。

在撰写本书时，OpenTelemetry 尚未准备好用于生产。OpenTelemetry 将提供与 OpenCensus 和 OpenTracing 的向后兼容性，还将提供安全补丁。在本书的下一节中，我们将了解如何使用 OpenCensus 实现 Go 程序。将来，使用 OpenTelemetry 实现您的程序应该相对简单，使用我们将在使用 OpenCensus 实现跟踪时讨论的策略

在下一节中，我们将看到如何为我们的应用程序实现 OpenCensus。

# 为应用程序实现 OpenCensus

让我们使用一个应用程序中 OpenCensus 跟踪的实际示例。为了开始，我们需要确保我们的机器上安装了 Docker。您应该能够在[使用安装文档 https://docs.docker.com/](https://docs.docker.com/) 以确保 Docker 已安装并在您的机器上正确运行。完成后，我们可以开始创建、实现和查看示例应用程序。一旦我们安装了 Docker，我们就可以为我们的仪器提取重要的图像。在我们的示例中，我们将使用 Redis（键值存储）在应用程序中存储键值事件，并使用 Zipkin（分布式跟踪系统）查看这些跟踪。

让我们提取此项目的依赖项：

1.  Redis 是我们将在示例应用程序中使用的键值存储：

```
docker pull redis:latest
```

2.  Zipkin 是一个分布式跟踪系统：

```
docker pull openzipkin/zipkin
```

3.  我们将安装 Redis 服务器，让它在后台运行：

```
docker run -it -d -p 6379:6379 redis
```

4.  我们将对 Zipkin 服务器执行相同的操作：

```
docker run -it -d -p 9411:9411 openzipkin/zipkin
```

一旦安装并准备好所有依赖项，我们就可以开始编写应用程序：

1.  首先，我们将实例化我们的`main`包并添加必要的导入：

```
package main

import (

    "context"
    "log"
    "net/http"
    "time"

    "contrib.go.opencensus.io/exporter/zipkin"
    "go.opencensus.io/trace"
    "github.com/go-redis/redis"
    openzipkin "github.com/openzipkin/zipkin-go"
    zipkinHTTP "github.com/openzipkin/zipkin-go/reporter/http"
)

```

2.  我们的`tracingServer`函数定义了一些东西：
    *   我们建立了一个新的 Zipkin 端点。
    *   我们初始化一个新的 HTTP reporter，它是我们向其发送跨距的端点。
    *   我们建立了一个新的导出器，它返回一个`trace.Exporter`（这就是我们上传跨度到 Zipkin 服务器的方式）。
    *   我们向跟踪处理程序注册我们的出口商。
    *   我们为采样率应用配置。在本例中，我们将示例设置为始终跟踪，但我们可以将此设置为请求的较小百分比：

```
func tracingServer() {

    l, err := openzipkin.NewEndpoint("oc-zipkin", "192.168.1.5:5454")

    if err != nil {
        log.Fatalf("Failed to create the local zipkinEndpoint: %v", err)

    }

    r := zipkinHTTP.NewReporter("http://localhost:9411/api/v2/spans")
    z := zipkin.NewExporter(r, l)
    trace.RegisterExporter(z)
    trace.ApplyConfig(trace.Config{DefaultSampler: trace.AlwaysSample()})

}
```

3.  在`makeRequest`函数中，我们执行以下操作：
    *   创建一个新的`span`
    *   向给定的 HTTP URL 发出请求
    *   设置睡眠超时以模拟额外的延迟
    *   注释我们的跨度
    *   返回响应状态

```
func makeRequest(ctx context.Context, url string) string {
    log.Printf("Retrieving URL")
    _, span := trace.StartSpan(ctx, "httpRequest")
    defer span.End()
    res, _ := http.Get(url)
    defer res.Body.Close()
    time.Sleep(100 * time.Millisecond)
    log.Printf("URL Response : %s", res.Status)
    span.Annotate([]trace.Attribute{
        trace.StringAttribute("URL Response Code", res.Status),
    }, "HTTP Response Status Code:"+res.Status)
    time.Sleep(50 * time.Millisecond)
    return res.Status
}
```

4.  在`writeToRedis`函数中，我们执行以下操作：
    *   开始新的跨越
    *   连接到我们的本地 Redis 服务器
    *   设置特定的键值对

```
func writeToRedis(ctx context.Context, key string, value string) {

    log.Printf("Writing to Redis")
    _, span := trace.StartSpan(ctx, "redisWrite")
    defer span.End()
    client := redis.NewClient(&redis.Options{
        Addr: "localhost:6379",
        Password: "",
        DB: 0,
    })

    err := client.Set(key, value, 0).Err()
    if err != nil {
        panic(err)
    }
}  
```

5.  然后，我们使用`main`函数将这一切结合在一起：

```
func main() {

    tracingServer()
    ctx, span := trace.StartSpan(context.Background(), "main")
    defer span.End()
    for i := 0; i < 10; i++ {
        url := "https://golang.org/"
        respStatus := makeRequest(ctx, url)
        writeToRedis(ctx, url, respStatus)
    }
} 
```

6.  在我们通过执行`go run ocZipkin.go`调用程序之后，我们可以查看我们的 Zipkin 服务器。如果我们选择跟踪列表中的一个跟踪，我们可以看到我们创建的跟踪：

![](assets/e4ba0a84-ea05-4651-a52d-9e2f91ffd6fd.png)

如果我们点击其中一个跨度，我们可以进一步调查：

![](assets/7b3555a8-7122-4f24-a795-d81fb40a5499.png)

我们可以在代码中看到对`httprequest`和`rediswrite`函数的调用。随着我们开始在代码周围实现更多的跨度，我们将获得越来越大的跟踪，这将帮助我们诊断代码延迟最大的地方。

如果单击跟踪中的一个单独元素，我们可以看到我们在代码中编写的注释：

![](assets/6310d60b-dd08-438f-9de5-66bd074a4783.png)

如果我们试图理解终端用户的特定行为，那么注释可能很有用。我们还可以看到`traceId`、`spanId`和`parentId`的详细信息。

# 总结

在这一章中，我们学习了所有关于痕迹的知识。我们学习了如何在特定的代码片段上实现单独的跟踪，并对它们进行分析以了解它们的行为。我们还学习了如何实现和分析分布式跟踪，以了解分布式系统中的问题。能够使用这些技能将有助于您调试分布式系统，进而有助于在对分布式系统进行故障排除时降低**平均解决时间**（**MTTR**。

在[第 14 章](13.html)、*集群和作业队列*中，我们将学习如何评估集群和作业队列以实现性能优化。