# 十、最大化性能

我们已经掌握了部署和启动应用程序的相关概念，在本章中，我们将锁定 Go 和相关第三方软件包中的高性能策略。

随着 web 服务或 API 的增长，性能问题可能会凸显出来。一个成功的 web 服务的一个标志是需要在堆栈后面有越来越多的马力；然而，通过编程的最佳实践来减少这种需求比简单地为应用程序提供更多的处理能力更好。

在本章中，我们将了解：

*   引入中间件以减少代码中的冗余，并为某些性能特性铺平道路
*   设计缓存策略以保持内容新鲜并尽快提供内容
*   使用基于磁盘的缓存
*   使用内存缓存
*   通过中间件限制 API 的速率
*   谷歌的 SPDY 协议倡议

在本章结束时，您应该知道如何将自己的中间件构建到您的社交网络（或任何其他 web 服务）中，以引入额外的功能，从而提高性能。

# 使用中间件降低成本

当使用 Go 中的 Web 时，路由和使用处理程序的内置方法并不总是适用于非常干净的现成中间件方法。

例如，尽管我们有一个非常简单的`UsersRetrieve()`方法，但如果我们想阻止消费者到达该点或在其之前运行某个东西，我们需要在代码中多次包含这些调用或参数：

```go
func UsersRetrieve(w http.ResponseWriter, r *http.Request) {
  CheckRateLimit()
```

另一个电话是：

```go
func UsersUpdate( w http.ResponseWriter, r *http.Request) {
  CheckRateLimit()
  CheckAuthentication()
}
```

中间件允许我们更清晰地指导应用程序的内部模式，因为我们可以根据前面代码中给出的速率限制和身份验证进行检查。如果有一些外部信号告诉我们应用程序应该暂时脱机而不完全停止应用程序，我们也可以绕过调用。

考虑到这些可能性，让我们考虑一下在应用程序中使用中间件的有用方法。

方法的最佳方式是找到我们通过复制插入了大量不必要代码的地方。一个容易开始的地方是我们的身份验证步骤，这些步骤作为潜在块存在于`api.go`文件的许多代码段中。请参阅以下内容：

```go
func UserLogin(w http.ResponseWriter, r *http.Request) {

  CheckLogin(w,r)
```

在整个应用程序中，我们多次调用`CheckLogin()`函数，因此我们可以将其转移到中间件中，以减少整个应用程序中的代码的粗糙和重复。

另一种方法是访问控制头设置，它允许或拒绝基于允许域的请求。我们将其用于一些事情，特别是用于绑定到 CORS 规则的服务器端请求：

```go
func UserCreate(w http.ResponseWriter, r *http.Request) {

 w.Header().Set("Access-Control-Allow-Origin", "*")
 for _, domain := range PermittedDomains {
 fmt.Println("allowing", domain)
 w.Header().Set("Access-Control-Allow-Origin", domain)
  }
```

这也可以由中间件处理，因为它不需要任何基于请求类型的定制。在我们希望设置允许域的任何请求中，我们都可以将此代码移动到中间件中。

总的来说，这代表了良好的代码设计，但如果没有自定义中间件处理程序，有时可能会很棘手。

中间件的一种流行方法是链接，其工作原理如下：

```go
firstFunction().then(nextFunction()).then(thirdFunction())
```

这在 Node.js 中非常常见，[T0]、[T1]和[T2]函数在代码中大量使用。在Go中也可以做到这一点。

这有两种主要的方法。第一种方法是在处理程序中包装处理程序。这通常被认为是丑陋的，不可取。

处理返回到其父级的包装处理程序函数可能是一场解析的噩梦。

那么，让我们来看看第二种方法：链接。有许多框架包括中间件链接，但是仅仅为了中间件链接而引入重型框架是不必要的。让我们看看如何在 Go 服务器中直接执行此操作：

```go
package main

import
(
  "fmt"
  "net/http"
)

func PrimaryHandler(w http.ResponseWriter, r *http.Request) {
  fmt.Fprintln(w, "I am the final response")
}

func MiddlewareHandler(h http.HandlerFunc) http.HandlerFunc {
  fmt.Println("I am middleware")
  return func(w http.ResponseWriter, r *http.Request) {
    h.ServeHTTP(w, r)
  }
}

func middleware(ph http.HandlerFunc, middleHandlers ..func(http.HandlerFunc) (http.HandlerFunc) ) http.HandlerFunc {
  var next http.HandlerFunc = ph
  for _, mw := range middleHandlers {
    next = mw(ph)
  }
  return next
}

func main() {
  http.HandleFunc("/middleware", middleware(PrimaryHandler,MiddlewareHandler))
  http.ListenAndServe(":9000",nil)
}
```

如前所述，在我们的代码和大多数基于服务器的应用程序中，中间件会非常有用。在本章后面，我们将研究将身份验证模型移动到中间件中，以减少我们在处理程序中进行的重复调用的数量。

然而，为了提高性能，这种中间件的另一个功能可以用作缓存查找的阻塞机制。如果我们想绕过`GET`请求中的潜在瓶颈，我们可以在请求和响应之间设置一个缓存层。

我们使用的是关系数据库，这是基于 web 的瓶颈最常见的来源之一；因此，在可以接受陈旧或不经常更改的内容的情况下，将生成的查询放置在这样一个屏障后面可以极大地提高 API 的整体性能。

鉴于我们有两种主要类型的请求可以以不同的方式从中间件中获益，我们应该说明如何针对各种请求采用中间件策略。

下图是我们如何构建中间件的模型。它可以作为在何处为特定类型的 API 调用实现特定中间件处理程序的基本指南：

![Using middleware to reduce cruft](img/image00217.jpeg)

所有请求都应该受到一定程度的速率限制，即使某些请求的速率限制比其他请求高得多。因此，`GET`、`PUT`、`POST`和`DELETE`请求将在每个请求上至少运行一个中间件。

任何带有其他动词（例如，[T0]）的请求都应该绕过此选项。

`GET`请求应该受到缓存的约束，我们也将缓存描述为使它们返回的数据在某种程度上可以修改。

另一方面，PUT、POST 和 DELETE 请求显然无法缓存，因为这将迫使我们的响应不准确，或者导致重复尝试创建或删除数据。

让我们从`GET`请求开始，看看两种相关的方法，当可以交付服务器缓存结果而不是访问关系数据库时，我们可以通过这两种方法绕过瓶颈。

## 缓存请求

当然，在任何给定的请求的生命周期中，有不止一种或两种方法可以诱导缓存。在本节中，我们将探讨其中的一些，以介绍最高级别的非冗余缓存。

在脚本或浏览器级别有客户端缓存，表面上绑定到从服务器端发送给它的规则。这里，我们的意思是屈服于 HTTP 响应头，例如`Cache-Control`、`Expires`、`If-None-Match`、`If-Modified-Since`等等。

这些是您可以强制执行的最简单的缓存控制形式，作为 RESTful 设计的一部分，它们也非常重要。然而，它们也有点脆弱，因为它们不允许执行那些指令和客户机，而这些指令和客户机很容易就会拒绝它们。

接下来，还有基于代理的缓存，通常是第三方应用程序，它们要么为任何给定请求的缓存版本提供服务，要么传递给原始服务器应用程序。当我们在 API 前面讨论使用 Apache 或 Nginx 时，我们看到了这方面的先兆。

最后，在应用程序级别有服务器级缓存。这通常是用来代替代理缓存的，因为两者往往在相同的规则集上操作。在大多数情况下，采用独立代理缓存是最明智的选择，但有时这些解决方案无法适应特定的边缘情况。

为了更好地理解代理缓存的缓存策略，从头开始设计这些缓存还有一些优点。让我们简要介绍一下如何以基于磁盘和基于内存的方式为社交网络构建服务器端应用程序缓存，并了解如何利用这一经验在代理级别更好地定义缓存规则。

## 简单的基于磁盘的缓存

不久前，大多数开发人员处理缓存请求的方式通常是在应用程序级别通过基于磁盘的缓存。

在这种方法中，围绕任何给定请求的缓存机制和限定符设置了一些参数。然后，请求的结果保存到字符串中，然后保存到锁定文件中。最后，锁文件被重命名。这个过程是相当稳定的，虽然它是过时的，并且工作得很好，足够可靠。

在网络的早期，有许多不利因素是无法克服的。

请注意，众所周知，磁盘，尤其是机械磁盘的存储和访问速度相对较慢，它们必然会导致文件系统和操作系统在查找、查找和排序方面出现许多问题。

分布式系统也提出了一个明显的挑战，即需要共享缓存来确保平衡请求之间的一致性。如果服务器 A 更新其本地缓存，并且下一个请求返回来自服务器 B 的缓存命中，则根据服务器的不同，您可以看到不同的结果。使用网络文件服务器可能会减少这一点，但会带来一些权限和网络延迟问题。

另一方面，没有什么比将请求的版本保存到文件更简单的了。这一点，加上基于磁盘的缓存在其他编程领域的悠久历史，使其成为一个自然的早期选择。

此外，认为基于磁盘的缓存时代已经结束并不完全公平。更快的驱动器（通常是 SSD）重新开启了使用非临时存储进行快速访问的潜力。

让我们来看看如何为我们的 API 设计一个基于磁盘的缓存中间件解决方案，以减少重载中的负载和瓶颈。

首先要考虑的是缓存什么。出于明显的原因，我们永远不会允许`PUT`、`POST`和`DELETE`请求进行缓存，因为我们不希望重复数据，也不希望对`DELETE`或`POST`请求做出错误响应，这些请求指示资源已经创建或删除，而事实上它还没有创建或删除。

因此，我们知道我们只是在缓存`GET`请求或数据列表。这是我们拥有的唯一可以“过时”的数据，因为我们可以接受一些过时的数据，而不必对应用程序的操作方式进行重大更改。

让我们从最基本的请求`/api/users`开始，它返回系统中的用户列表，并介绍一些用于缓存到磁盘的中间件。让我们将其设置为一个框架，以解释我们如何评估：

```go
package diskcache

import
(
)

type CacheItem struct {

}
```

我们的[T0]结构是包中唯一的真实元素。它由有效的缓存命中（以及有关缓存元素的信息，包括上次修改时间、内容等）或缓存未命中组成。缓存未命中将返回到我们的 API，该项不存在或已超过生存时间（TTL）。在这种情况下，`diskcache`包会将缓存设置为文件：

```go
func SetCache() {

}
```

这就是我们要做的。如果一个请求没有缓存响应或者缓存无效，我们需要返回结果以便保存它。这使得中间件部分有点棘手，但我们将很快向您展示如何处理这个问题。以下`GetCache()`函数查找我们的缓存目录，查找并返回缓存项（无论是否有效）或生成假值：

```go
func GetCache() (bool, CacheItem) {

}
```

下面的`Evaluate()`函数将是我们的主要入口点，如果我们需要创建或重新创建缓存条目，将传递到`GetCache()`或稍后可能传递到`SetCache()`：

```go
func Evaluate(context string, value string, in ...[]string) (bool, CacheItem) {

}
```

在这个结构中，我们将利用一个上下文（以便在请求类型之间进行划分）、结果值（用于保存）和一个开放的字符串变量，我们可以将其用作缓存项的限定符。这里，我们指的是强制生成唯一缓存文件的参数。假设我们指定`page`和`search`为两个这样的限定符。第 1 页请求将不同于第 2 页请求，它们将分别缓存。第 1 页搜索 Nathan 的请求与第 1 页搜索 Bob 的请求不同，依此类推。

这一点对于硬文件非常严格，因为我们需要以可靠且一致的方式命名（并查找）缓存文件，但在将缓存保存到数据存储中时，这一点也很重要。

考虑到所有这些，让我们检查一下如何识别可缓存条目

### 启用过滤

目前，我们的 API 不接受任何针对我们的`GET`请求的任何特定参数，这些请求返回实体列表或关于实体的特定细节。这里的示例包括用户列表、状态更新列表或关系列表。

您可能会注意到，我们的`UsersRetrieve()`处理程序现在返回下一页，以响应`start`值和`limit`值。目前，这是硬编码，起始值为`0`，极限值为`10`。

此外，我们正在设置一个`Pragma: no-cache`标题。我们显然不希望这样。因此，为了准备缓存，让我们添加两个附加字段，客户端可以使用这些字段按属性查找他们要查找的特定用户。

第一个是开始和限制，它指示排序分页。我们现在拥有的是：

```go
  start := 0
  limit := 10

  next := start + limit
```

让我们首先通过接受开始来响应请求：

```go
  start := 0
  if len(r.URL.Query()["start"]) > 0 {
    start = r.URL.Query()["start"][0]
  }
  limit := 10
  if len(r.URL.Query()["limit"]) > 0 {
    start = r.URL.Query()["limit"][0]
  }
  if limit > 50 {
    limit = 50
  }
```

现在，我们可以接受起始值和限制值。请注意，我们还对返回的结果数量设置了上限。超过 50 的任何结果都将被忽略，最多返回 50 个结果。

### 将磁盘缓存转换为中间件

现在我们将取`diskcache`的骨架，将转化为中间件调用，并开始加速我们的`GET`请求：

```go
package diskcache

import
(
  "errors"
  "io/ioutil"
  "log"
  "os"
  "strings"
  "sync"
  "time"
)

const(
 CACHEDIR = "/var/www/cache/"
)
```

这显然表示缓存文件的严格位置，但也可以将其分支到基于上下文的子目录中，例如，本例中的 API 端点。因此，`GET`请求中的`/api/users`将映射到`/var/www/cache/users/get/.`，这减少了单个目录中的数据量：

```go
var MaxAge int64  = 60
var(
  ErrMissingFile = errors.New("File Does Not Exist")
  ErrMissingStats = errors.New("Unable To Get File Stats")
  ErrCannotWrite = errors.New("Cannot Write Cache File")
  ErrCannotRead = errors.New("Cannot Read Cache File")
)

type CacheItem struct {
  Name string
  Location string
  Cached bool
  Contents string
  Age int64
}
```

我们的通用`CacheItem`结构由文件的名称、物理位置、秒数和内容组成，如以下代码所述：

```go
func (ci *CacheItem) IsValid(fn string) bool {
  lo := CACHEDIR + fn
  ci.Location = lo

  f, err := os.Open(lo)
  defer f.Close()
  if err != nil {
    log.Println(ErrMissingFile)
    return false
  }

  st, err := f.Stat()
  if err != nil {
    log.Println(ErrMissingStats)
    return false
  }

  ci.Age := int64(time.Since(st.ModTime()).Seconds())
  return (ci.Age <= MaxAge)
}
```

我们的`IsValid()`方法首先确定该文件是否存在并且是否可读，如果它早于`MaxAge`变量。如果无法读取或太旧，则返回 false，这告诉我们的`Evaluate()`条目点创建文件。否则，我们返回 true，它指示`Evaluate()`函数读取现有缓存文件。

```go
func (ci *CacheItem) SetCache() {
  f, err := os.Create(ci.Location)
  defer f.Close()
  if err != nil {
    log.Println(err.Error())
  } else {
    FileLock.Lock()
    defer FileLock.Unlock()
    _, err := f.WriteString(ci.Contents)
    if err != nil {
      log.Println(ErrCannotWrite)
    } else {
      ci.Age = 0
    }
  }
  log.Println(f)
}
```

在我们的进口部分，您可能会注意到，`sync`包被称为；`SetCache()`至少在生产环境中，应该使用互斥来诱导对文件操作的锁定。我们使用`Lock()`和`Unlock()`（延迟）来处理此问题。

```go
func (ci *CacheItem) GetCache() error {
  var e error
  d, err := ioutil.ReadFile(ci.Location)
  if err == nil {
    ci.Contents = string(d)
  }
  return err
}

func Evaluate(context string, value string, expireAge int64, qu ...string) (error, CacheItem) {

  var err error
  var ci CacheItem
  ci.Contents = value
  ci.Name = context + strings.Join(qu,"-")
  valid := ci.IsValid(ci.Name)
```

请注意，此处的文件名是通过将参数加入到`qu`可变参数中生成的。如果我们想对此进行微调，我们需要按字母顺序对参数进行排序，如果参数以不同的顺序提供，这将防止缓存未命中。

因为我们控制原始呼叫，所以风险很低。但是，由于这是作为共享库构建的，因此行为应该相当一致是很重要的。

```go
  if !valid {
    ci.SetCache()
    ci.Cached = false
  } else {
    err = ci.GetCache()
    ci.Cached = true
  }

  return err, ci
}
```

我们可以简单地使用一个只按值写入文件的小示例来测试这一点：

```go
package main

import
(
  "fmt"
  "github.com/nkozyra/api/diskcache"
)

func main() {
  err,c := diskcache.Evaluate("test","Here is a value that will only live for 1 minute",60)
  fmt.Println(c)
  if err != nil {
    fmt.Println(err)
  }
  fmt.Println("Returned value is",c.Age,"seconds old")
  fmt.Println(c.Contents)
}
```

如果我们运行这个，然后更改`Here is a value ...`的值，并在 60 秒内再次运行，我们将获得缓存的值。这表明我们的 diskcache 包可以保存和返回值，而不会遇到后端瓶颈。

现在，让我们将放在`UsersRetrieve()`处理程序前面，并提供一些可选参数。通过将我们的缓存设置为`page`和`search`作为可缓存参数，我们将减轻任何基于负载的对数据库的影响。

## 分布式内存中的缓存

与基于磁盘的缓存类似，我们使用简单的内存缓存绑定到单个实体键，尽管这仍然是磁盘缓存的有用替代方案。

用 Memcache（d）之类的东西替换磁盘将允许我们进行非常快速的检索，但在密钥方面不会给我们带来任何好处。此外，大量复制的可能性意味着通常比物理存储小的内存存储可能会成为一个问题。

然而，有许多方法可以潜入内存或分布式内存缓存。我们不会向您展示这种插入式替换，但是通过一个包含一个 NoSQL 解决方案的 segue，您可以轻松地将两种类型的缓存转换为严格的、仅内存的缓存选项。

## 使用 NoSQL 作为缓存存储

与 Memcache（d）不同，使用数据存储或数据库，我们能够基于非链接参数进行更复杂的查找。

例如，在我们的`diskcache`包中，我们将`page`和`search`等参数链接在一起，这样我们的键（在本例中是文件名）类似于`getusers_1_nathan.cache`。

必须以一致和可靠的方式生成这些密钥以进行查找，因为任何更改都会导致缓存未命中而不是预期命中，我们需要重新生成缓存请求，这将完全消除预期的好处。

对于数据库，我们可以对缓存请求执行非常详细的列查找，但是，考虑到关系数据库的性质，这不是一个好的解决方案。毕竟，我们专门构建了缓存层，以避免遇到诸如 RDBMS 之类的常见瓶颈。

举个例子，我们将再次利用 MongoDB 作为一种编译和查找缓存文件的方法，具有高吞吐量和高可用性，并具有为参数相关查询提供的额外灵活性。

在本例中，我们将添加一个基本文档，其中只包含一个页面、搜索、内容和一个修改过的字段。最后一个字段将用作分析的时间戳。

尽管`page`似乎是一个明显的整数字段，但我们将在 MongoDB 中将其创建为字符串，以避免在执行查询时进行类型转换。

```go
package memorycache
```

出于显而易见的原因，我们将其称为`memorycache`而不是 memcache，以避免任何潜在的混淆。

```go
import
(
  "errors"
  "log"
  mgo "gopkg.in/mgo.v2"
  bson "gopkg.in/mgo.v2/bson"
  _ "strings"
  "sync"
  "time"
)
```

我们已经用 MongoDB 软件包取代了[T1]任何操作系统和基于磁盘的软件包。BSON 包也包括在提出具体的`Find()`请求中。

### 提示

在生产环境中，在为此类意图寻找键值存储或内存存储时，应注意解决方案的锁定机制及其对读/写操作的影响。

```go
const(
  MONGOLOC = "localhost"
)

var MaxAge int64  = 60
var Session mgo.Session
var Collection *mgo.Collection

var(
  ErrMissingFile = errors.New("File Does Not Exist")
  ErrMissingStats = errors.New("Unable To Get File Stats")
  ErrCannotWrite = errors.New("Cannot Write Cache File")
  ErrCannotRead = errors.New("Cannot Read Cache File")

  FileLock sync.RWMutex
)

type CacheItem struct {
  Name string
  Location string
  Contents string
  Age int64
  Parameters map[string] string
}
```

这里值得注意的是，MongoDB 有一个数据过期的生存时间概念。这可能会消除手动使内容过期的必要性，但在其他商店平台上可能不可用。

```go
type CacheRecord struct {
  Id bson.ObjectId `json:"id,omitempty" bson:"_id,omitempty"`
  Page string
  Search string
  Contents string
  Modified int64
}
```

注意`CacheRecord`结构中的文字标识符；这些允许我们自动生成 MongoDB ID。如果没有这一点，MongoDB 将抱怨`_id_`上的索引重复。下面的`IsValid()`函数实际返回`diskcache`包中文件的相关信息。在`memorycache`版本中，我们将只返回一条信息，无论在请求的年龄内是否存在记录。

```go
func (ci *CacheItem) IsValid(fn string) bool {
  now := time.Now().Unix()
  old := now - MaxAge

  var cr CacheRecord
  err := Collection.Find(bson.M{"page":"1", "modified": bson.M{"$gt":old} }).One(&cr)
  if err != nil {
    return false
  } else {
    ci.Contents = cr.Contents
    return true
  }

  return false
}
```

还要注意，我们没有删除旧记录。这可能是保持缓存记录快速的逻辑下一步。

```go
func (ci *CacheItem) SetCache() {
  err := Collection.Insert(&CacheRecord{Id: bson.NewObjectId(), Page:ci.Parameters["page"],Search:ci.Parameters["search"],Contents:ci.Contents,Modified:time.Now().Unix()})
  if err != nil {
    log.Println(err.Error())
  }
}
```

无论我们是否找到一条记录，我们都会在前面的代码中插入一条新记录。当我们进行查找时，这会给我们提供最新的记录，并且也让我们在某种程度上有了修订控制的感觉。您还可以更新记录以避免版本控制。

```go
func init() {
  Session, err := mgo.Dial(MONGOLOC)
  if err != nil {
    log.Println(err.Error())
  }
  Session.SetMode(mgo.Monotonic, true)
  Collection = Session.DB("local").C("cache")
  defer Session.Ping()
}

func Evaluate(context string, value string, expireAge int64, param map[string]string) (error, CacheItem) {

  MaxAge = expireAge
  defer Session.Close()

  var ci CacheItem
  ci.Parameters = param
  ci.Contents = value
  valid := ci.IsValid("bah:")
  if !valid {
    ci.SetCache()
  }

  var err error

  return err, ci
}
```

这与`diskcache`的操作方式基本相同，只是我们在`param`哈希映射中提供了键/值对，而不是非结构化参数名列表。

所以，用法有一点变化。下面是一个例子：

```go
package main

import
(
  "fmt"
  "github.com/nkozyra/api/memorycache"
)

func main() {
  parameters := make( map[string]string )
  parameters["page"] = "1"
  parameters["search"] = "nathan"
  err,c := memorycache.Evaluate("test","Here is a value that will only live for 1 minute",60,parameters)
  fmt.Println(c)
  if err != nil {
    fmt.Println(err)
  }
  fmt.Println("Returned value is",c.Age,"seconds old")
  fmt.Println(c.Contents)
}
```

当我们运行它时，我们将在数据存储中设置内容，这将持续 60 秒，直到它变得无效并在第二行中重新创建缓存内容。

## 实现缓存作为中间件

为了将这个缓存放在所有`GET`请求的中间件链中，我们可以实现上面概述的策略，并添加一个缓存中间件元素。

使用前面的示例，我们可以使用`middleware()`函数在链的前端实现这一点：

```go
  Routes.HandleFunc("/api/users", middleware(DiskCache, UsersRetrieve, DiskCacheSave) ).Methods("GET")
```

这允许我们在`UsersRetrieve()`函数之前执行`DiskCache()`处理程序。但是，如果[T5]没有有效的缓存，我们还希望保存我们的响应，因此我们也会在最后调用[T2]。如果`DiskCache()`中间件处理程序接收到有效缓存，它将阻止该链。下面是它的工作原理：

```go
func DiskCache(h http.HandlerFunc) http.HandlerFunc {
  start := 0
  q := r.URL.Query()
  if len(r.URL.Query()["start"]) > 0 {
    start = r.URL.Query()["start"][0]
  }
  limit := 10
  if len(r.URL.Query()["limit"]) > 0 {
    limit = q["limit"][0]
  }
  valid, check := diskcache.Evaluate("GetUsers", "", MaxAge, start, limit)
  fmt.Println("Cache valid",valid)
  if check.Cached  {
    return func(w http.ResponseWriter, r *http.Request) {
      fmt.Fprintln(w, check.Contents)
    }
  } else {
    return func(w http.ResponseWriter, r *http.Request) {
      h.ServeHTTP(w, r)
    }
  }
}
```

如果我们得到`check.Cached`为真，我们只是提供内容。否则，我们继续。

在编写函数之前，需要对主函数进行一次小的修改，以便将内容转移到下一个函数：

```go
  r.CacheContents = string(output)
  fmt.Fprintln(w, string(output))
}
```

然后，`DiskCacheSave()`本质上可以是`DiskCache`的复制品，只是它会从`http.Request`功能中设置的实际内容：

```go
func DiskCacheSave(h http.HandlerFunc) http.HandlerFunc {
  start := 0
  if len(r.URL.Query()["start"]) > 0 {
    start = r.URL.Query()["start"][0]
  }
  limit := 10
  if len(r.URL.Query()["limit"]) > 0 {
    start = r.URL.Query()["limit"][0]
  }
  valid, check := diskcache.Evaluate("GetUsers", r.CacheContents, MaxAge, start, limit)
  fmt.Println("Cache valid",valid)
  return func(w http.ResponseWriter, r *http.Request) {
    h.ServeHTTP(w, r)
  }

}
```

## 在 Go 前使用前端缓存代理

我们工具箱中的另一个工具是使用前端缓存代理（正如我们在[第 7 章](07.html "Chapter 7. Working with Other Web Technologies")中所做的，*使用其他 Web 技术*作为我们面向缓存层的请求。

除了传统的 web 服务器（如 Apache 和 Nginx）之外，我们还可以使用几乎专门用于缓存的服务，这些服务可以替代、位于所述服务器的前面，或者与所述服务器并行。

不必深入研究这种方法，我们可以从应用程序外部复制一些性能更好的功能。如果我们至少不提这件事，那我们就是失职了。Nginx、Varnish、Squid 和 Apache 等工具都为反向代理服务器内置了缓存。

对于生产级部署，这些工具可能更成熟，更适合处理这一级别的缓存。

### 提示

您可以在[找到更多关于 Nginx 和反向代理缓存的信息 http://nginx.com/resources/admin-guide/caching/](http://nginx.com/resources/admin-guide/caching/) 。

Varnish 和[T0]Squid 也主要用于此级别的[T1]缓存。有关清漆和鱿鱼的更多详细信息，请访问[https://www.varnish-cache.org/](https://www.varnish-cache.org/) 和[http://www.squid-cache.org/](http://www.squid-cache.org/) 分别。

# Go 中的速率限制

在 API 中引入缓存可能是演示有效中间件策略的最简单方法。我们现在能够减轻交通拥挤的风险，并朝着

在 web 服务中，这种中间件功能的一个特别有用的地方是速率限制。

在高流量的 API 中存在速率限制，以允许消费者使用应用程序而不会潜在地滥用它。在这种情况下，滥用可能只是意味着过度访问会影响性能，也可能意味着对大规模数据采集产生威慑。

通常，人们会利用 API 创建整个数据收集的本地索引，从而有效地通过 API 对站点进行爬网。对于大多数应用程序，您都希望阻止这种访问。

在这两种情况下，对应用程序中的某些请求施加一些速率限制是有意义的。而且，重要的是，我们希望它足够灵活，这样我们就可以根据请求时间的不同限制来完成它。

我们可以使用许多因素来实现这一点，但最常用的两种方法如下：

*   通过相应的 API 用户凭据
*   通过请求的 IP地址

理论上，我们还可以通过对每个代理发出请求来对底层用户引入速率限制。在现实场景中，这将降低第三方应用程序因其用户使用而受到惩罚的风险。

重要的因素是在深入研究更复杂的调用之前，我们发现速率限制超过了符号，因为如果速率限制被超过，我们希望在这一点上打破中间件链。

对于这个速率限制中间件示例，我们将再次使用 MongoDB 作为请求存储和基于从午夜到午夜的日历日的限制。换言之，我们的每位用户限额在每天上午 12:01 重置。

存储实际请求只是一种方法。我们还可以读取 web 服务器日志或将其存储在内存中。然而，最轻量级的方法是将它们保存在数据存储中。

```go
package ratelimit

import
(
  "errors"
  "log"
  mgo "gopkg.in/mgo.v2"
  bson "gopkg.in/mgo.v2/bson"
  _ "strings"
  "time"
)

const(
  MONGOLOC = "localhost"
)
```

这就是我们的 MongoDB 主机。在这里，我们有一个包含日历日开始和结束边界的结构：

```go
type Requester struct {
  Id bson.ObjectId `json:"id,omitempty" bson:"_id,omitempty"`
  IP string
  APIKey string
  Requests int
  Timestamp int64
  Valid bool
}

type DateBounds struct {
  Start int64
  End int64
}
```

下面的`CreateDateBounds()`函数计算今天的日期，然后将`86400`秒添加到返回的`Unix()`值中（有效为 1 天）。

```go
var (
  MaxDailyRequests = 15
  TooManyRequests = errors.New("You have exceeded your daily limit of requests.")
  Bounds DateBounds
  Session mgo.Session
  Collection *mgo.Collection
)

func createDateBounds() {
  today := time.Now()
  Bounds.Start = time.Date(today.Year(), today.Month(), today.Day(), 0, 0, 0, 0, time.UTC).Unix()
  Bounds.End = Bounds.Start + 86400
}
```

使用下面的`RegisterRequest()`函数，我们只是将另一个请求记录到 API 中。在这里，我们只将请求绑定到 IP，添加身份验证密钥、用户 ID 或

```go
func (r *Requester) CheckDaily() {

  count, err := Collection.Find(bson.M{"ip": r.IP, "timestamp": bson.M{"$gt":Bounds.Start, "$lt":Bounds.End } }).Count()
  if err != nil {
    log.Println(err.Error())
  }
  r.Valid = (count <= MaxDailyRequrests)
}

func (r Requester) RegisterRequest() {
  err := Collection.Insert(&Requester{Id: bson.NewObjectId(), IP: r.IP, Timestamp: time.Now().Unix()})
  if err != nil {
    log.Println(err.Error())
  }

}
```

下面的代码是一个简单的标准初始化设置，除了的`createDateBounds()`函数，它只是设置我们查找的开始和结束：

```go
func init() {
  Session, err := mgo.Dial(MONGOLOC)
  if err != nil {
    log.Println(err.Error())
  }
  Session.SetMode(mgo.Monotonic, true)
  Collection = Session.DB("local").C("requests")
  defer Session.Ping()
  createDateBounds()
}
```

以下`CheckRequest()`功能作为整个流程的协调功能；它确定任何给定请求是否超过每日限制，并返回`Valid`状态属性：

```go
func CheckRequest(ip string) (bool) {
  req := Requester{ IP: ip }
  req.CheckDaily()
  req.RegisterRequest()

  return req.Valid
}
```

## 作为中间件实现速率限制

与缓存系统不同，将速率限制器转换为中间件要容易得多。IP 地址要么是速率受限的，要么不是速率受限的，我们继续前进。

下面是一个更新用户的示例：

```go
  Routes.HandleFunc("/api/users/{id:[0-9]+}", middleware(RateLimit,UsersUpdate)).Methods("PUT")
```

然后，我们可以引入一个`RateLimit()`中间件调用：

```go
func RateLimit(h http.HandlerFunc) http.HandlerFunc {
  return func(w http.ResponseWriter, r *http.Request) {
    if (ratelimit.CheckRequest(r.RemoteAddr) == false {
      fmt.Fprintln(w,"Rate limit exceeded")
    } else {
      h.ServeHTTP(w,r)
    }
  }
}
```

这允许我们在`ratelimit.CheckRequest()`调用失败时阻塞中间件链，并防止调用 API 中任何处理密集的部分。

# 实施 SPDY

如果你能对谷歌庞大的产品、平台和语言生态系统说一句话的话，那就是对一件跨越所有产品、平台和语言的永恒、一致的关注——对速度的需求。

### 注

我们在[第 7 章](07.html "Chapter 7. Working with Other Web Technologies")中简要提到了 SPDY 伪协议，*与其他 Web 技术*一起工作。您可以在[上阅读更多关于 SPDY 的白皮书 http://www.chromium.org/spdy/spdy-whitepaper](http://www.chromium.org/spdy/spdy-whitepaper) 。

随着谷歌（搜索引擎）迅速从一个学生项目扩展到地球上最受欢迎的网站，再到人们在任何地方都能找到任何东西的事实上的方式，扩展产品及其基础设施成为关键。

而且，如果你仔细想想，这个搜索引擎严重依赖于可用的站点；如果网站速度快，谷歌的爬行器和索引器会更快，结果也会更及时。

这在很大程度上是谷歌的*让我们让网络更快*活动背后的原因，该活动旨在帮助后端和前端的开发人员认识并推动将速度作为首要考虑因素。

谷歌还支持 SPDY 伪协议，该协议增强了 HTTP，并作为一组临时改进措施进行操作，其中许多改进措施正在进入 HTTP/2 的标准化阶段。

有很多 SPDY 实现都是为 Go 编写的，SPDY 似乎是一个特别受欢迎的项目，因为它在 Go 中还没有直接支持。大多数实现都是[T1]中[T0]的可互换插入式替换。在大多数实际情况下，您可以通过简单地将 SPDY 交给反向代理（如 HAProxy 或 Nginx）来获得这些好处。

### 注

以下是一些既实现安全连接又实现非安全连接的 SPDY 实现，值得检查和比较：

所罗门海克斯的`spdy.go`文件：[https://github.com/shykes/spdy-go](https://github.com/shykes/spdy-go)

杰米·霍尔的`spdy`文件：[https://github.com/SlyMarbo](https://github.com/SlyMarbo)

我们首先来看前面列表中的`spdy.go`。切换`ListenAndServe`函数是最简单的第一步，这种实现 SPDY 的方法相当常见。

以下是如何在我们的`api.go`文件中使用`spdy.go`作为替代品：

```go
  wg.Add(1)
  go func() {
    //http.ListenAndServeTLS(SSLport, "cert.pem", "key.pem", Routes)
    spdy.ListenAndServeTLS(SSLport, "cert.pem", "key.pem", Routes)
    wg.Done()
  }()
```

很简单吧？一些 SPDY 实现使得通过 SPDY 协议而不是[T0]提供的服务页面在语义上无法区分。

对于一些 Go 开发人员来说，这是一种惯用的方法。对于其他人来说，协议差异很大，因此有单独的语义是合乎逻辑的。这里的选择取决于你的喜好。

然而，还有一些其他的考虑因素需要考虑。首先，SPDY 引入了一些我们可以利用的附加特性。其中一些是像头压缩一样烘焙的。

## 检测 SPDY 支持

对于大多数客户端来说，检测[T0]SPDY 并不需要太担心，因为 SPDY 支持依赖于 TLS/SSL 支持。

# 总结

在本章中，我们研究了一些对高性能 API 非常重要的概念。这些主要包括通过使用自定义编写的中间件执行的速率限制以及磁盘和内存缓存。

利用本章中的示例，您可以实现任意数量的依赖中间件的服务，以保持代码整洁，并引入更好的安全性、更快的响应时间和更多功能。

在下一章（也是最后一章）中，我们将重点讨论特定于安全性的概念，这些概念应锁定速率限制、拒绝服务检测以及减少和防止代码和 SQL 注入尝试等其他问题。