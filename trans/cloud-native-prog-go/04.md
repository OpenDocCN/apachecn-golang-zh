# 使用消息队列的异步微服务体系结构

在过去的两章中，您学习了如何使用 Go 编程语言构建基于 REST 的微服务。REST 体系结构风格既简单又灵活，这使得它成为许多用例的最佳选择。但是，由于构建在 HTTP 之上，REST 体系结构中的所有通信都将遵循具有请求/应答事务的客户机/服务器模型。在某些用例中，这可能是限制性的，而其他通信模型可能更适合。

在本章中，我们将介绍发布/订阅通信模型，以及实现该模型所需的技术。通常，发布/订阅体系结构需要一个中央基础结构组件 MessageBroker。在开源世界中，有许多不同的消息代理实现；因此，在本章中，我们将介绍两种不同的消息代理，我们认为它们是最重要的消息代理之一-**RabbitMQ**和**Apache Kafka**。两者都适用于特定的用例；您将学习如何设置这两个消息代理中的每一个，如何连接 Go 应用程序，以及何时应该使用其中一个。

然后，我们将向您展示如何使用这些知识来扩展您在前几章中使用的事件管理微服务，以便在发生重要事件时发布事件。这使我们能够实现第二个监听这些事件的微服务。您还将了解通常与异步通信一起工作的高级体系结构模式，例如*事件协作*和*事件源*，以及如何（以及何时）在应用程序中使用它们。

在本章中，我们将介绍以下主题：

*   发布/订阅体系结构模式
*   活动协作
*   事件源
*   带 RabbitMQ 的 AMQP
*   阿帕奇·卡夫卡

# 发布/订阅模式

发布/订阅模式是众所周知的请求/应答模式的替代通信模式。发布/订阅体系结构由发布者和订阅者组成，而不是客户端（发出请求）和服务器（响应该请求）。

每个发布者都可以发出消息。真正收到这些消息的出版商不必担心。这是订户关心的问题；每个订户都可以订阅特定类型的消息，并在发布者发布给定类型的消息时收到通知。相反，每个订阅者并不关心消息的实际来源。

![](img/e967a901-db08-4ba1-a019-ab96d69ff7bc.png)

请求/应答和发布/订阅通信模式

实际上，许多发布/订阅体系结构需要一个中央基础结构组件 MessageBroker。发布者在 MessageBroker 上发布消息，订阅者在 MessageBroker 上订阅消息。然后，代理的主要任务之一是将已发布的消息路由到对它们感兴趣的订阅者。

通常，消息将基于主题路由**。这意味着每个发布者为发布的消息指定了一个主题（主题通常只是一个字符串标识符，例如，`user.created`）。每个订阅者还将订阅某个主题。通常，代理还允许订阅者使用通配符表达式（如`user.*`）订阅整个主题集。**

与请求/应答相比，发布/订阅模式带来了一些明显的优势：

*   发布者和订阅者之间的耦合非常松散。这甚至到了他们彼此都不知道的程度。
*   酒吧/酒吧体系结构非常灵活。可以添加新订阅服务器（从而扩展现有进程），而无需修改发布服务器。反之亦然；您可以添加新的发布服务器，而无需修改订阅服务器。
*   如果消息由消息代理路由，您还可以获得弹性。通常，MessageBroker 将所有消息存储在一个队列中，在订阅者处理完这些消息之前，这些消息一直保存在队列中。如果某个订阅服务器变得不可用（例如，由于故障或故意关机），则本应路由到该订阅服务器的消息将排队，直到该订阅服务器再次可用。
*   通常，您还将获得消息代理在协议级别上保证的某种可靠性。例如，RabbitMQ 通过要求每个订户确认接收到的消息来保证*可靠传递*。只有在确认消息后，代理才会从队列中删除该消息。如果订户在消息已经传递但尚未确认时失败（例如，断开连接），则消息将被放回消息队列。如果另一个订户侦听同一消息队列，则消息可能会路由到该订户；否则，它将保留在队列中，直到订阅服务器再次可用。
*   你可以很容易地扩展。如果单个订阅者发布的消息太多，无法有效处理这些消息，则可以添加更多订阅者，并让 message broker 负载平衡发送给这些订阅者的消息。

当然，引入中央基础设施组件（如 MessageBroker）也会带来风险。如果操作不当，您的 MessageBroker 可能会成为单点故障，在出现故障时会导致整个应用程序崩溃。在生产环境中引入 MessageBroker 时，您应该采取适当的措施来确保高可用性（通常通过集群和自动故障切换）。

如果您的应用程序在云环境中运行，您还可以利用云提供商提供的其中一种托管消息队列和传递服务，例如 AWS**简单队列服务**（**SQS**）或 Azure 服务总线。

在本章中，您将学习如何使用两种最流行的开源消息代理 RabbitMQ 和 ApacheKafka。在[第 8 章](08.html)、*AWS 第二部分——S3、SQS、API 网关和 DynamoDB*中，您将了解 AWS SQS。

# 介绍预订服务

在本节中，我们将首先使用 RabbitMQ 实现发布/订阅体系结构。为此，我们的架构需要新的微服务——预订服务将处理活动预订。其职责将包括确保活动不会超额预订。为此，它需要了解现有事件和位置。为了实现这一点，我们将修改**EventService**以在创建位置或事件时发出事件（是的，术语很混乱，请确保不要将*通知*类事件与*类金属板在此处播放*类事件弄错）。然后，**预订服务**可以监听这些事件，并在有人预订其中一个事件的票证时发出事件本身。

![](img/5e8ba22f-e4f5-4afe-a62e-a02471ec46b7.png)

概述我们的微服务及其将发布和订阅的事件

# 活动协作

事件协作描述了一种与事件驱动的发布/订阅体系结构协同工作的体系结构原则。

考虑下面的示例，该示例使用常规请求/应答通信模式，用户请求预订服务为某一事件预订机票。由于事件由另一个微服务（即**事件服务**管理，**预订服务**需要从**事件服务请求有关事件及其位置的信息。**只有这样**预订服务**才能检查是否还有座位，并将用户的预订保存在自己的数据库中。此事务所需的请求和响应如下图所示：

![](img/33a76190-6cbc-46dc-a92c-74f6f5cf3070.png)

请求和答复

现在，考虑在发布/订阅体系结构中的相同场景，其中，使用事件的 PosiTeService AutoT1 和 PoT T2aEngServices Ty3A.使用事件进行集成：每次在 ToeT4 服务 EngService Ty5 T5 中的数据更改时，它发出一个事件（例如，OutT6.创建了一个新的位置）创建了一个新事件，*更新了一个事件*等等）。

现在，**预订服务**可以收听这些事件。它可以建立自己的数据库，其中包含所有当前存在的位置和事件。现在，如果用户为给定的事件请求新的预订，**预订服务**可以简单地使用其本地数据库中的数据，而无需从其他服务请求此数据。有关此原理的另一个说明，请参阅下图：

![](img/42e36988-e61f-42cd-a54b-9e1133e416b3.png)

BookingService 使用其本地数据库中的数据

这是事件协作体系结构的关键点。在前面的图中，服务几乎不需要查询另一个服务的数据，因为它通过侦听其他服务发出的事件已经知道它需要知道的一切。

显然，这种体系结构模式与发布/订阅一起工作得非常好。在前面的示例中，**事件服务**将是发布者，**预订服务**（可能是其他）将是订阅者。当然，这一原则将不可避免地导致两个服务存储冗余数据，这一事实可能会让人望而却步。但是，这不一定是坏事，因为每个服务都会不断侦听其他服务发出的事件，所以整个数据集可以（最终）保持一致。此外，这增加了系统的整体弹性；例如，如果事件服务突然出现故障，**BookingService**将保持运行，因为它不再依赖事件服务来工作。

# 用 RabbitMQ 实现发布/订阅

在下一节中，您将学习如何实现基本的发布/订阅体系结构。为此，我们将了解**高级消息队列协议**（**AMQP**）及其最流行的实现之一 RabbitMQ。

# 高级消息队列协议

在协议级别上，RabbitMQ 实现 AMQP。在开始使用 RabbitMQ 之前，让我们先看看 AMQP 的基本协议语义。

AMQP 消息代理管理两种基本类型的资源—**交换**和**队列**。每个发布者将其邮件发布到 exchange 中。每个订阅服务器使用一个队列。AMQP 代理负责将在 exchange 中发布的消息放入相应的队列。消息发布到交换机后的去向取决于**交换机类型**和称为**绑定**的路由规则。AMQP 了解三种不同类型的交易所：

*   **直接交换**：消息发布时使用一个给定的主题（在 AMQP 中称为**路由键**，该主题是一个简单的字符串值。可以定义直接交换和队列之间的绑定以完全匹配该主题。
*   **扇出交换机**：消息路由到通过绑定连接到扇出交换机的所有队列。消息可以有路由密钥，但它将被忽略。每个绑定队列将接收在扇出交换中发布的所有消息。
*   **话题交流**：类似于直接交流。但是，队列现在使用消息的路由密钥必须匹配的模式绑定到 exchange。主题交换通常假设路由键用点字符`'.'`分割。例如，您的路由密钥可以遵循`"<entityname>.<state-change>.<location>"`模式（例如`"event.created.europe"`。您现在可以使用`'*'`或`'#'`字符创建可能包含通配符的队列绑定。`*`将匹配任何单个路由密钥段，而`#`将匹配任何数量的段。因此，对于前面的示例，有效绑定可能如下所示：
    *   `event.created.europe`（显然）
    *   `event.created.*`（在世界任何地方创建活动时收听）
    *   `event.#`（世界上任何地方的活动发生任何变化时，请倾听）
    *   `event.*.europe`（在欧洲活动发生任何变化时，请倾听）

下一个图中显示了一个可能的示例交换和队列拓扑。在本例中，我们有一个发布消息的服务，**事件服务**。我们有两个队列，消息将在其中路由。第一个队列**evts_booking**将接收与对事件进行的任何类型更改相关的任何和所有消息。第二个队列**evts_search**将只接收有关创建新事件的消息。请注意，**evts_ 预订**队列有两个订户。当两个或多个订阅者订阅同一队列时，MessageBroker 将轮流向其中一个订阅者发送消息。

![](img/cc668950-bec2-43b7-beb1-5ca489f7e80d.png)

MessageBroker 轮流向其中一个订阅者显示消息

需要注意的是，整个 AMQP 拓扑（意味着所有交换和队列以及它们如何相互绑定）不是由代理定义的，而是由发布者和消费者自己定义的。AMQP 指定了几种方法，客户端可以使用这些方法来声明所需的交换和队列。例如，发布者通常会使用`exchange.declare`方法来断言它想要发布的 exchange 实际上存在（如果它以前不存在，则代理将创建它）。另一方面，订阅者可以使用`queue.declare`和`queue.bind`方法来声明要订阅的队列，并将其绑定到交换机。

有多个开源消息代理实现 AMQP。最受欢迎的代理之一（也是我们将在本章中讨论的一个）是 RabbitMQ 代理，这是一个开源 AMQP 代理，由**Pivotal**开发，并根据**Mozilla 公共许可证**提供。实现 AMQP 的其他消息代理是**Apache QPID**（[https://qpid.apache.org](https://qpid.apache.org) 和**Apache ActiveMQ**（[http://activemq.apache.org](http://activemq.apache.org) 。

虽然在本例中我们将使用 RabbitMQ，但本章中编写的代码将适用于各种 AMQP 实现。

# 带 Docker 的 RabbitMQ 快速启动

在构建发布/订阅体系结构之前，您需要在开发环境中设置一个正在运行的 RabbitMQ 消息代理。开始使用 RabbitMQ 最简单的方法是使用正式的 Docker 映像。

对于本例，我们将假设您在本地计算机上安装了一个正常工作的 Docker。查看官方安装说明，了解如何在操作系统上安装 Docker，网址为：[https://docs.docker.com/engine/installation](https://docs.docker.com/engine/installation) 。

您可以在命令行上使用以下命令启动新的 RabbitMQ 代理：

```go
$ docker run --detach \ 
    --name rabbitmq \ 
    -p 5672:5672 \ 
    -p 15672:15672 \ 
    rabbitmq:3-management 
```

前面的命令将在您的计算机上创建一个名为`rabbitmq`的新容器。为此，Docker 将使用`rabbitmq:3-management`图像。此映像包含 RabbitMQ 3 的最新版本（在撰写本文时为 3.6.6）和管理 UI。`-p 5672:5672`标志将指示 Docker 将 TCP 端口`5672`（为 AMQP 分配的 IANA 端口号）映射到您的`localhost`地址。`-p 15672:15672`标志将对管理用户界面执行相同的操作。

启动容器后，您将能够打开到`amqp://localhost:5672`的 AMQP 连接，并在您的浏览器`http://localhost:15672`中打开管理 UI。

在 Windows 上使用 Docker 时，需要用本地 Docker 虚拟机的 IP 地址替换 localhost。您可以使用命令行上的以下命令确定此 IP 地址：`$ docker-machine ip default`。

无论您使用的是 docker 机器还是本地 docker 安装，RabbitMQ 用户界面都应该与以下屏幕截图中的用户界面非常相似：

![](img/6075ceff-4af4-4e70-bfa2-de38dd0501c0.png)

RabbitMQ 的管理用户界面

在浏览器中打开管理界面（`http://localhost:15672`或 docker 机器 IP 地址）。RabbitMQ 映像提供了一个默认的来宾用户，其密码也是`guest`。当然，在生产环境中运行 RabbitMQ 时，这是您应该更改的第一件事。出于开发目的，它会做得很好。

# 高级 RabbitMQ 设置

上一节中描述的基于 Docker 的设置允许您快速入门，并且（经过一些调整）也适用于生产设置。如果您不想将 Docker 用于 MessageBroker，还可以从包存储库在最常见的 Linux 发行版上安装 RabbitMQ。例如，在 Ubuntu 和 Debian 上，可以使用以下命令安装 RabbitMQ：

```go
$ echo 'deb http://www.rabbitmq.com/debian/ testing main' | \ 
    sudo tee /etc/apt/sources.list.d/rabbitmq.list 
$ wget -O- https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | \ 
    sudo apt-key add - 
$ apt-get update 
$ apt-get install -y rabbitmq-server 
```

类似的命令也适用于**CentOS**和**RHEL**：

```go
$ rpm --import https://www.rabbitmq.com/rabbitmq-release-signing-key.asc 
$ yum install rabbitmq-server-3.6.6-1.noarch.rpm 
```

对于生产设置，您可能需要考虑将 RabBMQ 设置为群集以确保高可用性。请查看[上的官方文件 http://www.rabbitmq.com/clustering.html](http://www.rabbitmq.com/clustering.html) 了解有关如何设置 RabbitMQ 群集的更多信息。

# 连接 RabbitMQ 和 Go

为了连接到 RabbitMQ 代理（或任何 AMQP 代理），我们建议您使用`github.com/streadway/amqp`库（这是 AMQP 事实上的标准 Go 库）。让我们从安装库开始：

```go
$ go get -u github.com/streadway/amqp
```

然后可以从将库导入代码开始。使用`amqp.Dial`方法打开一个新连接：

```go
import "github.com/streadway/amqp" 

func main() { 
  connection, err := amqp.Dial("amqp://guest:guest@localhost:5672") 
  if err != nil { 
    panic("could not establish AMQP connection: " + err.Error()) 
  } 

  defer connection.Close() 
} 
```

在本例中，`"amqp://guest:guest@localhost:5672"`是您的 AMQP 代理的 URL。请注意，用户凭据嵌入到 URL 中。`amqp.Dial`方法在成功时返回一个连接对象，或者返回`nil`和一个错误，否则返回一个错误（与 Go 中的通常情况一样，确保您实际检查了这个错误）。另外，当您不再需要时，不要忘记使用`Close()`方法关闭连接。

当然，在应用程序中硬编码这些连接细节（更少的凭据）通常不是一个好的做法。还记得您在十二要素应用程序中学到的内容吗，让我们介绍一个环境变量`AMQP_URL`，我们可以使用它动态配置 AMQP 代理：

```go
import "github.com/streadway/amqp" 
import "os" 

func main() { 
  amqpURL := os.Getenv("AMQP_URL"); 
  if amqpURL == "" { 
    amqpURL = "amqp://guest:guest@localhost:5672" 
  } 

  connection, err := amqp.Dial(amqpURL) 
  // ... 
} 
```

在 AMQP 中，大多数操作不是直接在连接上完成的，而是在通道上完成的。通道用于在一个实际 TCP 连接上*多路复用*多个虚拟连接。

通道本身不是线程安全的。在 Go 中，我们需要记住这一点，并注意不要从多个 Goroutine 访问同一个通道。但是，使用多个通道（每个通道仅由一个线程访问）是完全安全的。因此，当有疑问时，最好创建一个新的渠道。

通过在现有连接上创建新通道继续：

```go
connection, err := amqp.Dial(amqpURL) 
if err != nil { 
  panic("could not establish AMQP connection: " + err.Error()) 
} 

channel, err := connection.Channel() 
if err != nil { 
  panic("could not open channel: " + err.Error()) 
} 
```

现在，我们可以将此通道对象用于一些实际的 AMQP 操作，例如，发布消息和订阅消息。

# 发布和订阅 AMQP 消息

在回到 MyStices 微型服务体系结构之前，让我们看看我们可以使用的基本 AMQP 方法。为此，我们将首先构建一个能够将消息发布到 exchange 的小示例程序。

打开通道后，消息发布者应声明要将消息发布到的 exchange。为此，您可以在通道对象上使用`ExchangeDeclare()`方法：

```go
err = channel.ExchangeDeclare("events", "topic", true, false, false, false, nil) 
if err != nil { 
  panic(err) 
} 
```

正如您所看到的，`ExchangeDeclare`需要相当多的参数。详情如下:

*   交换名称
*   交换类型（记住 AMQP 知道`direct`、`fanout`和`topic`交换）
*   当代理重新启动时，`durable`标志将使交易所保持声明状态
*   `autoDelete`标志将导致在声明关闭的通道关闭后立即删除交换机
*   `internal`标志将阻止发布者将消息发布到此队列中
*   `noWait`标志将指示`ExchangeDeclare`方法不要等待代理的成功响应
*   `args`参数可能包含带有附加配置参数的映射

声明交换后，现在可以发布消息。为此，您可以使用通道的`Publish()`方法。发出的消息将是您首先需要实例化的`amqp.Publishing`结构的实例：

```go
message := amqp.Publishing { 
  Body: []byte("Hello World"),
} 
```

然后，使用`Publish()`方法发布您的消息：

```go
err = channel.Publish("events", "some-routing-key", false, false, message) 
if err != nil { 
  panic("error while publishing message: " + err.Error()) 
} 
```

`Publish()`方法采用以下参数：

*   要发布到的 exchange 的名称
*   邮件的路由密钥
*   `mandatory`标志将指示代理确保消息实际路由到至少一个队列中
*   `immediate`标志将指示代理确保消息实际传递给至少一个订户
*   `msg`参数包含要发布的实际消息

对于发布/订阅体系结构，发布者不需要知道谁在订阅其发布的消息，`mandatory`和`immediate`标志显然不合适，因此在本例中我们只需将它们设置为 false（以及以下所有标志）。

您现在可以运行这个程序，它将连接到您的本地 AMQP 代理，声明一个交换，并发布一条消息。当然，此消息不会被路由到任何地方并消失。为了实际处理它，您需要一个订户。

继续创建第二个 Go 程序，在该程序中连接到 AMQP 代理，并创建一个新的频道，如前一节所述。但是，现在，让我们声明一个队列并将其绑定到该 exchange，而不是声明一个 exchange 并发布一条消息：

```go
_, err = channel.QueueDeclare("my_queue", true, false, false, false, nil) 
if err != nil { 
  panic("error while declaring the queue: " + err.Error()) 
} 

err = channel.QueueBind("my_queue", "#", "events", false, nil) 
if err != nil { 
  panic("error while binding the queue: " + err.Error())
} 
```

声明并绑定队列后，现在可以开始使用此队列。为此，请使用通道的`Consume()`功能：

```go
msgs, err := channel.Consume("my_queue", "", false, false, false, false, nil) 
if err != nil { 
  panic("error while consuming the queue: " + err.Error()) 
} 
```

`Consume()`方法采用以下参数：

*   要使用的队列的名称。
*   唯一标识此使用者的字符串。当保留为空时（如本例中），将自动生成唯一标识符。
*   当设置`autoAck`标志时，接收到的消息将被自动确认。如果未设置，则需要在使用接收到的消息的`Ack()`方法处理消息后显式确认消息（请参见下面的代码示例）。
*   设置`exclusive`标志时，该消费者将是唯一允许使用该队列的消费者。未设置时，其他使用者可能会侦听同一队列。
*   `noLocal`标志向代理指出，不应向该消费者传递在同一通道上发布的消息。
*   `noWait`标志指示库不要等待代理的确认。
*   `args`参数可能包含带有附加配置参数的映射。

在本例中，`msgs`将是`amqp.Delivery`结构的通道（这一次，意味着实际的 Go 通道，而不是 AMQP 通道）。为了从队列接收消息，我们可以简单地从该通道读取值。如果您想连续阅读消息，最简单的方法是使用`range`循环：

```go
for msg := range msgs { 
  fmt.Println("message received: " + string(msg.Body)) 
  msg.Ack(false) 
} 
```

请注意，我们在前面的代码中使用`msg.Ack`函数显式确认消息。这是必要的，因为我们已经在前面将`Consume()`函数的`autoAck`参数设置为 false。

明确确认消息具有重要作用如果您的消费者在接收和确认消息之间由于任何原因失败，消息将被放回队列，然后重新传递给另一个消费者（如果没有其他消费者，则留在队列中）。因此，消费者只应在完成消息处理后确认消息。如果消息在消费者实际处理之前被确认（这是`autoAck`参数会导致的），然后消费者意外死亡，消息将永远丢失。因此，明确确认消息是使系统具有弹性和容错能力的重要步骤。

# 构建事件发射器

在前面的示例中，我们使用 AMQP 通道将简单的字符串消息从发布服务器发送到订阅服务器。为了使用 AMQP 构建实际的发布/订阅体系结构，我们需要使用结构化数据传输更复杂的消息。通常，每个 AMQP 消息只是一个字节字符串。要提交结构化数据，我们可以使用序列化格式，如 JSON 或 XML。此外，由于 AMQP 不限于 ASCII 消息，我们还可以使用二进制序列化协议，如`MessagePack`或`ProtocolBuffers`。

对于您决定的任何序列化格式，您都需要确保发布服务器和订阅服务器都了解消息的序列化格式和实际内部结构。

关于序列化格式，我们将在本章中进行简单的选择，并使用 JSON 序列化格式。它被广泛采用；串行化和非串行化消息可以使用 Go 标准库以及其他编程语言轻松完成（这一点很重要，尽管在本书中我们专门承诺使用 Go，但在微服务体系结构中，有许多不同的应用程序运行时是很常见的）。

我们还需要确保发布者和订阅者都知道消息的结构。例如，`LocationCreated`事件可能有`name`属性和`address`属性。为了解决这个问题，我们将引入一个共享库，其中包含所有可能事件的结构定义，以及 JSON（un）序列化的说明。然后，该库可以在发布者和所有订阅者之间共享。

首先在 GOPATH 中创建`todo.com/myevents/contracts`目录。我们将描述的第一个事件类型是`EventCreatedEvent`事件。创建新事件后，事件服务将发布此消息。让我们将此事件定义为新创建包的`event_created.go`文件中的结构：

```go
package contracts 

import "time" 

type EventCreatedEvent struct { 
  ID         string    `json:"id"` 
  Name       string    `json:"id"` 
  LocationID string    `json:"id"` 
  Start      time.Time `json:"start_time"` 
  End        time.Time `json:"end_time"` 
} 
```

此外，我们还需要为每个事件生成一个主题名（在 RabbitMQ 中，主题名也将用作消息的路由键）。为此，在新定义的结构中添加一个新方法-`EventName()`：

```go
func (e *EventCreatedEvent) EventName() string { 
  return "event.created" 
} 
```

我们现在可以使用 Go 接口来定义通用事件类型。此类型可用于强制每个事件类型实际实现一个`EventName()`方法。由于事件发布者和事件订阅者稍后也将在多个服务中使用，因此我们将把事件接口代码放入`todo.com/myevents/lib/msgqueue`包中。首先，在该包中创建包目录和新文件`event.go`：

```go
package msgqueue 

type Event interface { 
  EventName() string 
} 
```

当然，我们的示例应用程序使用的事件不仅仅是`EventCreatedEvent`。例如，我们还有一个`LocationCreatedEvent`和一个`EventBookedEvent`。由于以打印方式显示它们的所有实现是相当重复的，因此我们希望在本章中参考示例文件。

现在让我们继续构建一个事件发射器，它可以将这些消息发布到 AMQP 代理。由于我们还将在本章后面的章节中探讨其他消息代理，因此我们将从定义任何事件发射器应该实现的接口开始。为此，在之前创建的`msgqueue`包中创建一个包含以下内容的`emitter.go`文件：

```go
package msgqueue 

type EventEmitter interface { 
  Emit(event Event) error 
} 
```

该接口描述了所有事件发射器实现需要实现的方法（实际上，只有一种方法）。现在让我们继续创建一个带有`emitter.go`文件的`todo.com/myevents/lib/msgqueue/amqp`子包。此文件将包含`AMQPEventEmitter`的结构定义。

考虑下面的代码示例：

```go
package amqp 

import "github.com/streadway/amqp" 

type amqpEventEmitter struct { 
  connection *amqp.Connection 
} 
```

注意`amqpEventEmitter`类型是如何声明为包私有的，因为它是用小写名称声明的。这将防止用户直接实例化`amqpEventEmitter`类型。对于正确的实例化，我们将提供一个构造函数方法。

接下来，让我们添加一个`setup`方法，我们可以使用它来声明此发布服务器将发布到的 exchange：

```go
func (a *amqpEventEmitter) setup() error {
   channel, err := a.connection.Channel()
   if err != nil {
     return err
   }

   defer channel.Close() 

  return channel.ExchangeDeclare("events", "topic", true, false, false, false, nil) 
 } 
```

您可能想知道为什么我们用这个方法创建了一个新的 AMQP 通道，并在声明交换后立即关闭它。毕竟，我们可以在以后发布消息时重用同一个通道。我们马上就到。

继续添加构造函数-`NewAMQPEventEmitter`-以构建此结构的新实例：

```go
func NewAMQPEventEmitter(conn *amqp.Connection) (EventEmitter, error) { 
  emitter := &amqpEventEmitter{ 
    connection: conn, 
  } 

  err := emitter.setup()
   if err != nil { 
    return nil, err 
  } 

  return emitter, nil 
} 
```

现在，到了`amqpEventEmitter`事件的实际核心`Emit`方法。首先，我们需要将作为参数传递到方法中的事件转换为 JSON 文档：

```go
import "encoding/json"

 // ...

 func (a *amqpEventEmitter) Emit(event Event) error { 
  jsonDoc, err := json.Marshal(event) 
  if err != nil { 
    return err 
  } 
} 
```

接下来，我们可以创建一个新的 AMQP 频道，并将我们的消息发布到事件交换：

```go
func (a *amqpEventEmitter) Emit(event Event) error { 
  // ... 

  chan, err := a.connection.Channel(); 
  if err != nil { 
    return err 
  } 

  defer chan.Close() 

  msg := amqp.Publishing{ 
    Headers:     amqpTable{"x-event-name": event.EventName()}, 
    Body:        jsonDoc, 
    ContentType: "application/json", 
  } 

  return chan.Publish( 
    "events", 
    event.EventName(), 
    false, 
    false, 
    msg 
  ) 
} 
```

注意，我们使用了`amqp.Publishing`的`Headers`字段在一个特殊的消息头中添加事件名称。这将使我们以后更容易实现事件侦听器。

另外，请注意，我们正在为代码中每个已发布的消息创建一个新通道。虽然从理论上讲，可以重用同一通道来发布多条消息，但我们需要记住，单个 AMQP 通道不是线程安全的。这意味着从多个 go 例程调用事件发射器的`Emit()`方法可能会导致奇怪和不可预测的结果。这正是 AMQP 频道要解决的问题；通过使用多个通道，多个线程可以使用相同的 AMQP 连接。

接下来，我们可以将新的事件发射器集成到您在[第 2 章](02.html)、*使用 Rest API 构建微服务*和[第 3 章](03.html)、*保护微服务*中已经构建的现有事件服务中。首先在`ServiceConfig`结构中添加 AMQP 代理的配置选项：

```go
type ServiceConfig struct { 
  // ... 
  AMQPMessageBroker string `json:"amqp_message_broker"` 
} 
```

这允许您通过 JSON 配置文件指定 AMQP 代理。在`ExtractConfiguration()`函数中，我们还可以添加一个回退，可以选择从环境变量中提取此值（如果设置）：

```go
func ExtractConfiguration(filename string) ServiceConfig { 
  // ... 

  json.NewDecoder(file).Decode(&conf) 
  if broker := os.Getenv("AMQP_URL"); broker != "" { 
    conf.AMQPMessageBroker = broker 
  } 

  return conf 
} 
```

我们现在可以使用此配置选项在事件服务的`main`函数中构造一个新的事件发射器：

```go
package main 

// ... 
import "github.com/streadway/amqp" 
import msgqueue_amqp "todo.com/myevents/lib/msgqueue/amqp" 

func main() { 
  // ... 

  config := configuration.ExtractConfiguration(*confPath) 
  conn, err := amqp.Dial(config.AMQPMessageBroker) 
  if err != nil { 
    panic(err) 
  } 

  emitter, err := msgqueue_amqp.NewAMQPEventEmitter(conn) 
  if err != nil { 
    panic(err) 
  } 

  // ... 
} 
```

我们现在可以将此事件发射器传递到`rest.ServeAPI`函数中，而`rest.ServeAPI`函数又可以将其传递到`newEventHandler`函数中：

```go
func ServeAPI(endpoint string, dbHandler persistence.DatabaseHandler, eventEmitter msgqueue.EventEmitter) error { 
  handler := newEventHandler(dbHandler, eventEmitter) 
  // ... 
} 
```

然后，事件发射器可以作为字段存储在`eventServiceHandler`结构中：

```go
type eventServiceHandler struct { 
  dbhandler persistence.DatabaseHandler 
  eventEmitter msgqueue.EventEmitter 
} 

func newEventHandler(dbhandler persistence.DatabaseHandler, eventEmitter msgqueue.EventEmitter) *eventServiceHandler { 
  return &eventServiceHandler{ 
    dbhandler: dbhandler, 
    eventEmitter: eventEmitter, 
  } 
} 
```

现在，`eventServiceHandler`保存了对事件发射器的引用，您可以在实际的 REST 处理程序中使用它。例如，这允许您在通过 API 创建新事件时发出`EventCreatedEvent`。为此，对`eventServiceHandler`的`newEventHandler`方法进行如下修改：

```go
func (eh *eventServiceHandler) newEventHandler(w http.ResponseWriter, r *http.Request) { 
  id, err := eh.dbhandler.AddEvent(event) 
  if err != nil { 
    // ... 
  } 

  msg := contracts.EventCreatedEvent{ 
    ID: hex.EncodeToString(id), 
    Name: event.Name, 
    LocationID: event.Location.ID, 
    Start: time.Unix(event.StartDate, 0), 
    End: time.Unix(event.EndDate, 0), 
  } 
  eh.eventEmitter.emit(&msg) 

  // ... 
} 
```

# 构建事件订阅服务器

现在，我们可以使用`EventEmitter`在`RabbitMQ`代理上发布事件，我们还需要一种监听这些事件的可能性。这就是我们将在本节中构建的`EventListener`的目的。

与前面一样，让我们从定义所有事件侦听器（AMQP 事件侦听器就是其中之一）应该实现的接口开始。为此，在`todo.com/myevents/lib/msgqueue`包中创建`listener.go`文件：

```go
package msgqueue 

type EventListener interface { 
  Listen(eventNames ...string) (<-chan Event, <-chan error, error) 
} 
```

此接口看起来与事件发射器的接口大不相同。这是因为每次调用事件发射器的`Emit()`方法都会立即发布一条消息。但是，事件侦听器通常会长时间处于活动状态，并且需要在收到传入消息时对其作出反应。这反映在我们的`Listen()`方法的设计中：首先，它将接受事件侦听器应该侦听的事件名称列表。然后它将返回两个 Go 通道：第一个通道将用于流式传输事件侦听器接收到的任何事件。第二个将包含在接收这些事件时发生的任何错误。

通过在`todo.com/myevents/lib/msgqueue/amqp`包中创建一个新的`listener.go`文件，开始构建 AMQP 实现：

```go
package amqp 

import "github.com/streadway/amqp" 

type amqpEventListener struct { 
  connection *amqp.Connection 
  queue      string 
} 
```

与事件发射器类似，继续添加一个`setup`方法。在此方法中，我们需要声明侦听器将使用的 AMQP 队列：

```go
func (a *ampqEventListener) setup() error { 
  channel, err := a.connection.Channel() 
  if err != nil { 
    return nil 
  } 

  defer channel.Close() 

  _, err := channel.QueueDeclare(a.queue, true, false, false, false, nil) 
  return err 
} 
```

请注意，侦听器将使用的队列的名称可以使用`amqpEventListener`结构的`queue`字段进行配置。这是因为稍后，多个服务将使用事件侦听器来侦听它们的事件，并且每个服务都将为此需要自己的 AMQP 队列。

您可能已经注意到，我们还没有将新声明的队列实际绑定到事件交换。这是因为我们还不知道我们实际上需要监听哪些事件（还记得`Listen`方法的`events`参数吗？）。

最后，让我们添加一个构造函数来创建新的 AMQP 事件侦听器：

```go
func NewAMQPEventListener(conn *amqp.Connection, queue string) (msgqueue.EventListener, error) { 
  listener := &amqpEventListener{ 
    connection: conn, 
    queue:      queue, 
  } 

  err := listener.setup() 
  if err != nil { 
    return nil, err 
  } 

  return listener, nil 
} 
```

有可能构建新的 AMQP 事件监听器，让我们实现实际的`Listen()`方法。首先要做的是使用`eventNames`参数并相应地绑定事件队列：

```go
func (a *amqpEventListener) Listen(eventNames ...string) (<-chan msgqueue.Event, <-chan error, error) { 
  channel, err := a.connection.Channel() 
  if err != nil { 
    return nil, nil, err 
  } 

  defer channel.Close() 

  for _, eventName := range eventNames { 
    if err := channel.QueueBind(a.queue, eventName, "events", false, nil); err != nil { 
      return nil, nil, err 
    } 
  } 
} 
```

接下来，我们可以使用通道的`Consume()`方法从队列接收消息：

```go
func (a *amqpEventListener) Listen(eventNames ...string) (<-chan msgqueue.Event, <-chan error, error) { 
  // ... 

  msgs, err := channel.Consume(a.queue, "", false, false, false, false, nil) 
  if err != nil { 
    return nil, nil, err 
  } 
} 
```

`msgs`变量现在保存一个`amqp.Delivery`结构的通道。但是，我们的事件侦听器应该返回一个通道`msgqueue.Event`。这可以通过在我们自己的 goroutine 中使用`msgs`通道来解决，构建相应的事件结构，然后在我们从该函数返回的另一个通道中发布它们：

```go
func (a *amqpEventListener) Listen(eventNames ...string) (<-chan msgqueue.Event, <-chan error, error) { 
  // ... 

  events := make(chan msgqueue.Event) 
  errors := make(errors) 

  go func() { 
    for msg := range msgs { 
      // todo: Map message to actual event struct 
    } 
  }() 

  return events, errors, nil 
} 
```

棘手的部分现在在内部 goroutine 中。这里，我们需要将原始 AMQP 消息映射到一个实际的事件结构（如前面定义的`EventCreatedEvent`）。

还记得 EventEmitter 在发布事件时如何向 AMQP 消息添加额外的`x-event-name`头吗？这是我们现在可以用来将这些消息映射回它们各自的结构类型的东西。让我们首先从 AMQP 消息头中提取事件名称：

以下所有代码都进入`Listen`方法的内部`range`循环。

```go
rawEventName, ok := msg.Headers["x-event-name"] 
if !ok { 
  errors <- fmt.Errorf("msg did not contain x-event-name header") 
  msg.Nack(false) 
  continue 
} 

eventName, ok := rawEventName.(string) 
if !ok { 
  errors <- fmt.Errorf( 
    "x-event-name header is not string, but %t", 
    rawEventName 
  ) 
  msg.Nack(false) 
  continue 
} 
```

前面的代码试图从 AMQP 消息中读取`x-event-name`头。由于`msg.Headers`属性基本上是一个`map[string]interface{}`，我们需要一些映射索引和类型断言，直到我们能够实际使用事件名称为止。如果收到的消息不包含所需的标头，则会将错误写入错误通道。此外，消息将被 nack'ed（否定确认的缩写），向代理表明它无法成功处理。

知道事件名称后，我们可以使用一个简单的 switch/case 构造从此名称创建一个新的事件结构：

```go
var event msgqueue.Event 

switch eventName { 
  case "event.created": 
    event = new(contracts.EventCreatedEvent) 
  default: 
    errors <- fmt.Errorf("event type %s is unknown", eventName) 
    continue 
} 

err := json.Unmarshal(msg.Body, event) 
if err != nil { 
  errors <- err 
  continue 
} 

events <- event 
```

# 建立预订服务

现在我们有了一个事件侦听器，我们可以使用它来实现预订服务。它的总体架构将遵循事件服务的架构，因此我们不会在这方面做太多的详细介绍。

首先创建一个新的包`todo.com/myevents/bookingservice`并创建一个新的`main.go`文件：

```go
package main 

import "github.com/streadway/amqp" 
import "todo.com/myevents/lib/configuration" 
import msgqueue_amqp "todo.com/myevents/lib/msgqueue/amqp" 
import "flag" 

func main() { 
  confPath := flag.String("config", "./configuration/config.json", "path to config file") 
  flag.Parse() 
  config := configuration.ExtractConfiguration(*confPath) 

  dblayer, err := dblayer.NewPersistenceLayer(config.Databasetype, config.DBConnection) 
  if err != nil { 
    panic(err) 
  } 

  conn, err := amqp.Dial(config.AMQPMessageBroker) 
  if err != nil { 
    panic(err) 
  } 

  eventListener, err := msgqueue_amqp.NewAMQPEventListener(conn) 
  if err != nil { 
    panic(err) 
  } 
} 
```

这将设置带有数据库连接和工作事件侦听器的预订服务。我们现在可以使用此事件侦听器来侦听事件服务发出的事件。为此，添加新的子包`todo.com/myevents/bookingservice/listener`并创建新的`event_listener.go\`文件：

```go
package listener 

import "log" 
import "todo.com/myevents/lib/msgqueue" 
import "todo.com/myevents/lib/persistence" 
import "gopkg.in/mgo.v2/bson" 

type EventProcessor struct { 
  EventListener msgqueue.EventListener 
  Database      persistence.DatabaseHandler 
} 

func (p *EventProcessor) ProcessEvents() error { 
  log.Println("Listening to events...") 

  received, errors, err := p.EventListener.Listen("event.created") 
  if err != nil { 
    return err 
  } 

  for { 
    select { 
      case evt := <-received: 
        p.handleEvent(evt) 
      case err = <-errors: 
        log.Printf("received error while processing msg: %s", err) 
    } 
  } 
} 
```

在`ProcessEvents()`函数中，我们调用事件侦听器的`Listen`函数来侦听新创建的事件。`Listen`函数返回两个通道，一个用于接收消息，另一个用于监听过程中发生的错误。然后，我们将使用一个无限运行的 for 循环和一个 select 语句同时从这两个通道读取数据。接收到的事件将被传递到`handleEvent`函数（我们仍然需要写入），接收到的错误将简单地打印到标准输出。

让我们继续使用`handleEvent`函数：

```go
func (p *EventProcessor) handleEvent(event msgqueue.Event) { 
  switch e := event.(type) { 
    case *contracts.EventCreatedEvent: 
      log.Printf("event %s created: %s", e.ID, e) 
      p.Database.AddEvent(persistence.Event{ID: bson.ObjectId(e.ID)}) 
    case *contracts.LocationCreatedEvent: 
      log.Printf("location %s created: %s", e.ID, e) 
      p.Database.AddLocation(persistence.Location{ID: bson.ObjectId(e.ID)}) 
    default: 
      log.Printf("unknown event: %t", e) 
  } 
} 
```

此函数使用类型开关来确定传入事件的实际类型。目前，我们的事件监听器通过将两个事件`EventCreated`和`LocationCreated`存储在它们的本地数据库中来处理它们。

在本例中，我们使用共享库`todo.com/myevents/lib/persistence`来管理数据库访问。这只是为了方便。在真正的微服务体系结构中，单个微服务通常使用完全独立的持久层，这些持久层可能构建在完全不同的技术堆栈上。

在我们的`main.go`文件中，我们现在可以实例化`EventProcessor`并调用`ProcessEvents()`函数：

```go
func main() { 
  // ... 

  eventListener, err := msgqueue_amqp.NewAMQPEventListener(conn) 
  if err != nil { 
    panic(err) 
  } 

  processor := &listener.EventProcessor{eventListener, dblayer} 
  processor.ProcessEvents() 
} 
```

除了收听活动外，预订服务还需要实现自己的 RESTAPI，用户可以使用该 API 预订指定活动的门票。这将遵循您在[第 2 章](02.html)、*使用 Rest API 构建微服务*和[第 3 章](03.html)、*保护微服务*中已经了解的相同原则。因此，我们将不再详细解释预订服务的 RESTAPI，而只描述其中的亮点。您可以在本章的代码示例中找到 REST 服务的完整实现。

在`main.go`文件中，我们需要将`processor.ProcessEvents()`调用移动到它自己的 go 例程中。否则，它将阻塞，程序将永远无法到达`ServeAPI`方法调用：

```go
func main() { 
  // ... 

  processor := &listener.EventProcessor{eventListener, dblayer} 
  go processor.ProcessEvents() 

  rest.ServeAPI(config.RestfulEndpoint, dbhandler, eventEmitter) 
} 
```

最后，我们将继续讨论实际的请求处理程序。已在`/events/{eventID}/bookings`注册申请投递；它检查当前为该活动安排了多少预订，以及该活动的地点是否仍有能力再预订一次。在这种情况下，它将创建并保存一个新预订，并发出一个`EventBooked`事件。查看示例文件以查看完整的实现。

# 事件源

使用异步消息传递构建应用程序为应用一些高级体系结构模式打开了大门，您将在本节中了解其中一种模式。

使用消息传递、发布/订阅和事件协作时，整个系统状态中的每一个更改都会以事件的形式反映出来，该事件由一个参与服务发出。通常，这些服务中的每一个都有自己的数据库，对系统状态保持自己的视图（至少在需要的情况下），并通过不断侦听其他服务发布的事件来保持最新状态。

然而，系统状态中的每一个更改也由一个已发布的事件表示，这一事实提供了一个有趣的机会。假设有人将任何人发布的每个事件都记录并保存到事件日志中。理论上（以及在实践中），您可以使用此事件日志重建整个系统状态，而不必依赖任何其他类型的数据库。

作为一个例子，考虑下面的（小）事件日志：

1.  上午 8:00 创建了名为 Alice 的用户#1
2.  上午 9:00 创建了名为 Bob 的用户#2
3.  下午 1:00 用户#1 已被删除
4.  下午 3:00 用户#2 将名称更改为 Cedric

通过重播这些事件，很容易在一天结束时重新构建系统的状态，因为有一个名为 Cedric 的用户。然而，还有更多。由于每个事件都有时间戳，因此可以重构应用程序在任何给定时间点的状态（例如，在上午 10:00，应用程序有两个用户，Alice 和 Bob）。

除了时间点恢复，事件源还为您提供了一个完整的审核日志，记录系统中发生的一切。在许多情况下，审计日志记录本身通常是一项实际需求，但也使系统在出现错误时更容易调试。拥有完整的事件日志允许您在准确的时间点复制系统的状态，然后逐步重播事件以实际再现特定错误。

此外，拥有事件日志可以减少单个服务对其本地数据库的依赖。在极端情况下，您可以完全放弃数据库，让每个服务在每次启动时从内存中的事件日志重建其整个查询模型。

# 使用 ApacheKafka 实现发布/订阅和事件源

在本章的剩余部分中，我们将不构建自己的活动来源系统。以前，我们使用 RabbitMQ 来完成服务之间的消息传递。但是，RabbitMQ 只处理消息调度，因此，如果需要包含所有事件的事件日志，则需要通过侦听所有事件并持久化它们来实现它。您还需要自己处理事件重播。

ApacheKafka 是一个分布式消息代理，它还附带一个集成的事务日志。它最初是由 LinkedIn 构建的，并作为一个开放源代码产品在 Apache 许可下获得许可。

在上一节中，我们已经使用 AMQP 连接构建了`EventEmitter`和`EventListener`接口的实现。在本节中，我们将使用 Kafka 实现相同的接口。

# 带 Docker 的卡夫卡快速入门

与 RabbitMQ 相反，ApacheKafka 的设置要复杂一些。Kafka 本身需要一个有效的 Zookeeper 设置，以便执行领导者选举、管理集群状态和持久化集群范围的配置数据。但是，出于开发目的，我们可以使用`spotify/kafka`图像。此图像附带内置 Zookeeper 安装，可以快速轻松地进行设置。

与之前的 RabbitMQ 映像一样，使用`docker run`命令快速启动：

```go
$ docker run -d --name kafka -p 9092:9092 spotify/kafka
```

这将启动单节点 Kafka 实例并将其绑定到本地主机 TCP 端口`9092`。

# 阿帕奇·卡夫卡的基本原理

Kafka 提供了发布/订阅消息代理，但并不基于 AMQP，因此使用了不同的术语。

卡夫卡的第一个基本概念是主题。主题类似于订阅服务器可以写入的类别或事件名称。它包含发布到此主题中的所有消息的完整日志。每个主题被划分为可配置数量的分区。发布新消息时，它需要包含分区键。代理使用分区键来决定消息应该写入主题的哪个分区。

![](img/228af662-564a-48ba-90ca-d1c11e87a40f.png)

每个卡夫卡主题由可配置数量的分区组成；每个已发布的消息都有一个分区键，用于决定消息应保存到哪个分区中

Kafka 代理保证，在每个分区中，消息的顺序将与它们发布时的顺序相同。对于每个主题，消息将保留一个可配置的保留期。但是，当事务日志变大时，代理的性能不会显著降低。因此，完全可以使用无限保留期操作 Kafka，并以此方式将其用作事件日志。当然，你需要考虑所需的磁盘存储将按比例增长。幸运的是，卡夫卡很好地支持水平扩展。

从每个主题中，任意数量的订阅者（卡夫卡行话中称为*消费者*）都可以阅读信息，任意数量的出版商（*制作人*也可以撰写信息。每个使用者在事件日志中为自己定义要开始使用的偏移量。例如，仅在内存中操作的新初始化的使用者可以从开始（偏移量=`0`）读取整个事件日志，以重建其整个查询模型。另一个拥有本地数据库且只需要在某个时间点之后发生的新事件的使用者可以在稍后开始读取事件日志。

每个消费者都是消费者组的成员。在给定主题中发布的消息将发布给每组的一个消费者。这可以用于实现发布/订阅通信，类似于我们已经用 AMQP 构建的通信。下图说明了使用 AMQP 和 Kafka 的发布/订阅体系结构中的不同术语和参与者。在这两种情况下，在 exchange/主题中发布的每条消息都将路由到每个使用者。

![](img/27552bd3-67e3-4bf0-9a6b-7a99d8bdef10.png)

发布/订阅 AMQP（1）和 Apache Kafka（2）；在 exchange/主题中发布的每条消息都会路由到每个订阅者

在 AMQP 中，您还可以让多个订阅者监听同一队列。在这种情况下，传入消息将不会路由到所有订阅服务器，而是路由到其中一个已连接的订阅服务器。这可用于在不同订户实例之间构建某种负载平衡。

通过将多个订户实例放入同一消费者组中，可以在 Kafka 中构建相同的应用程序。但是，在 Kafka 中，每个订阅者都被分配到一组固定的（可能是多个）分区。因此，可以并行使用主题的使用者数量受到主题分区数量的限制。下图说明了此示例：

![](img/00d574d2-a4b6-4166-a6c2-9b88b89e846a.png)

使用 AMQP（1）和 Apache Kafka（2）实现负载平衡；在 exchange/主题中发布的每封邮件都路由到一个已连接的订阅服务器

如果您决定让同一消费者组中的多个消费者订阅主题的同一分区，那么代理只需将该分区中的所有消息分派给最后连接的消费者。

# 用围棋连接卡夫卡

在本章前面的章节中，当我们连接到 AMQP 代理时，我们使用了事实上的标准库`github.com/streadway/amqp`。对于连接到 Kafka 代理，在可用的 Go 库中有更多的多样性。在撰写本书时，Go 最受欢迎的 Kafka 客户端库如下：

1.  `github.com/Shopify/sarama`提供完整的协议支持，采用纯 Go 实现。它是根据麻省理工学院许可证授权的。它得到积极维护。
2.  `github.com/elodina/go_kafka_client`也在纯 Go 中实现。它提供了比`Shopify`库更多的功能，但似乎没有那么积极地维护。它是根据 Apache 许可证授权的。
3.  `github.com/confluentinc/confluent-kafka-go`为`librdkafka`C 库提供了一个 Go 包装器（这意味着您需要在系统上安装`librdkafka`才能使该库工作）。据报道，它比`Shopify`库更快，因为它依赖于高度优化的 C 库。但出于同样的原因，它可能很难构建。尽管它的社区似乎比`Shopify`图书馆小，但它仍在积极维护。

对于本章，我们将使用`github.com/Shopify/sarama`库。通过`go get`开始安装：

```go
$ go get github.com/Shopify/sarama
```

在前面的章节中，我们已经在`todo.com/myevents/lib/msgqueue`包中定义了`EventEmitter`和`EventListener`接口。在本节中，我们现在将为这两个接口添加替代实现。在潜水之前，让我们快速查看一下如何使用 AutoT3 库来连接到卡夫卡代理，一般来说。

无论您打算发布还是使用消息，都需要先实例化一个`sarama.Client`结构。为此，您可以使用`sarama.NewClient`功能。为了实例化一个新客户机，您需要一个 Kafka 代理地址列表（请记住，Kafka 是为在集群中操作而设计的，因此您可以同时连接到多个集群代理）和一个配置对象。创建配置对象的最简单方法是`sarama.NewConfig`函数：

```go
import "github.com/Shopify/sarama" 

func main() { 
  config := sarama.NewConfig() 
  brokers := []string{"localhost:9092"} 
  client, err := sarama.NewClient(brokers, config) 

  if err != nil { 
    panic(err) 
  } 
} 
```

当然，使用`localhost`作为单个代理在开发设置中可以很好地工作。对于生产设置，应从环境中读取代理列表：

```go
func main() { 
  brokerList := os.Getenv("KAFKA_BROKERS") 
  if brokerList == "" { 
    brokerList = "localhost:9092" 
  } 

  brokers := strings.Split(brokerList, ",") 
  config := sarama.NewConfig() 

  client, err := sarama.NewClient(brokers, config) 
  // ... 
} 
```

您可以使用`config`对象微调卡夫卡连接的各种参数。不过，在大多数情况下，默认设置都可以。

# 用卡夫卡发布消息

Sarama 库提供了两种发布消息的实现，`sarama.SyncProducer`和`sarama.AsyncProducer`。

`AsyncProducer`提供了一个异步接口，该接口使用 Go 通道来发布消息和检查这些操作是否成功。它允许消息的高吞吐量，但如果您只想发出一条消息，那么使用起来就有点笨重。出于这个原因，`SyncProducer`提供了一个更简单的接口，该接口接收消息进行生成并阻塞，直到从代理收到消息已成功发布到事件日志的确认。

您可以使用`sarama.NewSyncProducerFromClient`和`sarama.NewAsyncProducerFromClient`函数实例化一个新的生产者。在我们的示例中，我们将使用您可以创建的`SyncProducer`，如下所示：

```go
producer, err := sarama.NewSyncProducerFromClient(client) 
if err != nil { 
  panic(err) 
} 
```

让我们继续使用`SyncProducer`创建`EventEmitter`接口的卡夫卡实现。首先创建`todo.com/myevents/lib/msgqueue/kafka`包和该包中的`emitter.go`文件：

```go
package kafka 

type kafkaEventEmitter struct { 
  producer sarama.SyncProducer 
} 
```

通过添加用于实例化此结构的构造函数继续：

```go
func NewKafkaEventEmitter(client sarama.Client) (msgqueue.EventEmitter, error) { 
  producer, err := sarama.NewSyncProducerFromClient(client) 
  if err != nil { 
    return nil, err 
  } 

  emitter := &kafkaEventEmitter{ 
    producer: producer, 
  } 

  return emitter, nil 
} 
```

为了发出消息，您需要构造一个`sarama.ProducerMessage`结构的实例。为此，您需要主题（在本例中，主题由`msgqueue.Event`的`EventName()`方法提供）和实际的消息体。主体需要作为`sarama.Encoder`接口的实现提供。您可以使用`sarama.ByteEncoder`和`sarama.StringEncoder`类型简单地将字节数组或字符串类型转换为`Encoder`实现：

```go
func (e *kafkaEventEmitter) Emit(event msgqueue.Event) error { 
  jsonBody, err := json.Marshal(event) 
  if err != nil { 
    return err 
  } 

  msg := &sarama.ProducerMessage{ 
    Topic: event.EventName(), 
    Value: sarama.ByteEncoder(jsonBody), 
  } 

  _, _, err = e.producer.SendMessage(msg) 
  return err 
} 
```

这个代码示例中的关键是生产者的`SendMessage()`方法。请注意，我们实际上忽略了此方法的一些返回值。前两个返回值返回消息写入的分区编号和消息在事件日志中的偏移量编号。

前面的代码可以工作，但有一个致命的缺陷：它为每个事件类型创建一个新的卡夫卡主题。虽然订阅者完全有可能同时使用多个主题，但您将无法保证处理顺序。这可能导致生产者以短顺序依次发射`location #1 created`和`location #1 updated`，而订户以另一顺序接收它们。

为了解决这个问题，我们需要做两件事：

*   所有邮件必须发布在同一主题上。这意味着我们需要另一种方法来在消息中存储实际的事件名称。
*   每条消息必须公开一个分区密钥。我们可以使用消息的分区键来确保有关同一实体（即，同一事件、同一用户）的消息存储在事件日志的单个分区中，并按顺序路由到同一使用者。

让我们从分区键开始。还记得`todo.com/myevents/lib/msgqueue`包中的`Event`接口吗？看起来是这样的：

```go
package msgqueue 

type Event interface { 
  EventName() string 
} 
```

继续向该界面添加新方法`PartitionKey()`：

```go
package msgqueue 

type Event interface { 
  PartitionKey() string 
  EventName() string 
} 
```

接下来，我们可以修改之前定义的现有事件结构（例如，`EventCreatedEvent`，以实现这个`PartitionKey()`方法：

```go
func (e *EventCreatedEvent) PartitionKey() string { 
  return e.ID 
} 
```

现在，让我们回到`kafkaEventEmitter`。我们现在可以在向卡夫卡发布消息时使用每个事件的`PartitionKey()`方法。现在，我们只需要将事件名称与事件一起发送。为了解决这个问题，我们将为消息体使用一个信封：这意味着消息体不仅包含 JSON 序列化的事件对象，还包含另一个可以包含元数据（如事件名称）和实际事件体作为有效负载的对象。让我们在包`todo.com/myevents/lib/msgqueue/kafka`中的新文件`payload.go`中定义此事件：

```go
package kafka 

type messageEnvelope struct { 
  EventName string      `json:"eventName"` 
  Payload   interface{} `json:"payload"` 
} 
```

我们现在可以调整`kafkaEventEmitter`，首先构造`messageEnvelope`结构的实例，然后 JSON 序列化：

```go
func (e *kafkaEventEmitter) Emit(event msgqueue.Event) error { 
  envelope := messageEnvelope{event.EventName(), event} 
  jsonBody, err := json.Marshal(&envelope) 
  // ... 
```

# 使用来自卡夫卡的消息

使用来自 Kafka 代理的消息比在 AMQP 中要复杂一点。您已经了解到，Kafka 主题可能由许多分区组成，每个使用者可以使用其中的一个或多个（最多）分区。Kafka 体系结构通过将主题划分为多个分区并让一个使用者订阅每个分区，从而允许水平扩展。

这意味着每个订阅者都需要知道主题的哪些分区存在，以及应该使用哪些分区。我们在本节前面介绍的一些库（特别是合流库）实际上支持自动订户分区和自动组平衡。`sarama`库不提供此功能，因此我们的`EventListener`需要手动选择要使用的分区。

在我们的示例中，我们将实现`EventListener`，以便它在默认情况下侦听主题的所有可用分区。我们将添加一个特殊属性，该属性可用于显式指定要侦听的分区。

在`todo.com/myevents/lib/msgqueue/kafka`包中新建一个文件`listener.go`：

```go
package kafka 

import "github.com/Shopify/sarama" 
import "todo.com/myevents/lib/msgqueue" 

type kafkaEventListener struct { 
  consumer   sarama.Consumer 
  partitions []int32 
} 
```

通过为此结构添加构造函数继续：

```go
func NewKafkaEventListener(client sarama.Client, partitions []int32) (msgqueue.EventListener, error) { 
  consumer, err := sarama.NewConsumerFromClient(client) 
  if err != nil { 
    return nil, err 
  } 

  listener := &kafkaEventListener{ 
    consumer: consumer, 
    partitions: partitions, 
  } 

  return listener, nil 
} 
```

`kafkaEventListener`的`Listen()`方法与前面章节实现的`amqpEventListener`接口相同：

```go
func (k *kafkaEventListener) Listen(events ...string) (<-chan msgqueue.Event, <-chan error, error) { 
  var err error 

  topic := "events" 
  results := make(chan msgqueue.Event) 
  errors := make(chan error) 
} 
```

首先要做的是确定应该使用哪些主题分区。我们将假设，当一个空片段被传递到`NewKafkaEventListener`方法时，侦听器应该侦听所有分区：

```go
func (k *kafkaEventListener) Listen(events ...string) (<-chan msgqueue.Event, <-chan error, error) { 
  var err error 

  topic := "events" 
  results := make(chan msgqueue.Event) 
  errors := make(chan error) 

  partitions := k.partitions 
  if len(partitions) == 0 { 
    partitions, err = k.consumer.partitions(topic) 
    if err != nil { 
      return nil, nil, err 
    } 
  } 

  log.Printf("topic %s has partitions: %v", topic, partitions) 
} 
```

Sarama 使用者只能使用一个分区。如果我们想要使用多个分区，我们将需要启动多个使用者。为了保留`EventListener`的接口，我们将启动多个使用者，每个使用者在`Listen()`方法中各自的 goroutine 中，然后让它们都写入相同的结果通道：

```go
func (k *kafkaEventListener) Listen(events ...string) (<-chan msgqueue.Event, <-chan error, error) { 
  // ... 

  log.Printf("topic %s has partitions: %v", topic, partitions) 

  for _, partitions := range partitions { 
    con, err := k.consumer.ConsumePartition(topic, partition, 0) 
    if err != nil { 
      return nil, nil, err 
    } 

    go func() { 
      for msg := range con.Messages() { 

      } 
    }() 
  } 
} 
```

请注意在第一个 for 循环中启动的 goroutine。其中每一个都包含一个内部 for 循环，该循环迭代给定分区中接收的所有消息。现在，我们可以对传入的消息进行 JSON 解码，并重构适当的事件类型。

以下所有代码示例都位于`kafkaEventListener`的`Listen()`方法的内部 for 循环中。

```go
for msg := range con.Messages() { 
  body := messageEnvelope{} 
  err := json.Unmarshal(msg.Value, &body) 
  if err != nil { 
    errors <- fmt.Errorf("could not JSON-decode message: %s", err) 
    continue 
  } 
} 
```

我们现在有一个新问题。我们已将事件主体解组为一个`messageEnvelope`结构。其中包含事件名称和实际事件正文。但是，事件主体的类型仅为`interface{}`。理想情况下，我们需要根据事件名称将此`interface{}`类型转换回正确的事件类型（例如`contracts.EventCreatedEvent`。为此，我们可以使用您可以通过 go-get 安装的`github.com/mitchellh/mapstructure`软件包：

```go
$ go get -u github.com/mitchellh/mapstructure
```

`mapstructure`库的工作原理与`encoding/json`库类似，只是它不接受`[]byte`输入变量，而是通用`interface{}`输入值。这允许您获取未知结构的 JSON 输入（通过对`interface{}`值调用`json.Unmarshal`，然后将已解码的未知结构类型映射到已知结构类型：

```go
for msg := range con.Messages() { 
  body := messageEnvelope{} 
  err := json.Unmarshal(msg.Value, &body) 
  if err != nil { 
    errors <- fmt.Errorf("could not JSON-decode message: %s", err) 
    continue 
  } 

  var event msgqueue.Event 
  switch body.EventName { 
    case "event.created": 
      event = contracts.EventCreatedEvent{} 
    case "location.created": 
      event = contracts.LocationCreatedEvent{} 
    default: 
      errors <- fmt.Errorf("unknown event type: %s", body.EventName) 
      continue 
  } 

  cfg := mapstructure.DecoderConfig{ 
    Result: event, 
    TagName: "json", 
  } 
  err = mapstructure.NewDecoder(&cfg).Decode(body.Payload) 
  if err != nil { 
    errors <- fmt.Errorf("could not map event %s: %s", body.EventName, err) 
  } 
} 
```

在实际解码之前创建的`mapstructure.DecoderConfig`结构中的`TagName`属性指示`mapstructure`库尊重事件契约中已经存在的现有``json:"..."``注释。

成功解码消息后，可以将其发布到结果通道：

```go
for msg := range con.Messages() { 
  // ...   
  err = mapstructure.NewDecoder(&cfg).Decode(body.Payload) 
  if err != nil { 
    errors <- fmt.Errorf("could not map event %s: %s", body.EventName, err) 
  } 

  results <- event 
} 
```

我们的卡夫卡事件监听器现在功能齐全。由于它实现了`msgqueue.EventListener`接口，您可以使用它作为现有 AMQP 事件侦听器的替代品。

不过，有一个警告。启动时，我们当前的 Kafka 事件侦听器总是从事件日志的一开始就开始使用。仔细看看前面代码示例中的`ConsumePartition`调用，它的第三个参数（在我们的例子中，`0`描述了事件日志中消费者应该开始消费的偏移量。

使用`0`作为偏移量将指示事件侦听器从一开始就读取整个事件日志。如果您想使用 Kafka 实现事件源，这是理想的解决方案。如果您只想将 Kafka 用作消息代理，您的服务将需要记住从事件日志中读取的最后一条消息的偏移量。重新启动服务后，您可以从最后一个已知位置恢复消费。

# 总结

在本章中，您学习了如何使用消息队列（如 RabbitMQ 和 ApacheKafka）通过异步通信集成多个服务。您还了解了一些体系结构模式，如事件协作和事件源，这些模式可以帮助您构建非常适合云部署的可伸缩和弹性应用程序。

我们在本章中使用的技术与任何特定的云提供商都没有关联。您可以在任何云基础设施或您自己的服务器上轻松推出您自己的 RabbitMQ 或 Kafka 基础设施。在[第 8 章](08.html)、*AWS 第二部分——S3、SQS、API 网关和 DynamoDB*中，我们将再次关注消息队列，特别关注 AWS 为您提供的托管消息解决方案。